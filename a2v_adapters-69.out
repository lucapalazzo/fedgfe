Wed Jan 21 10:26:22 AM UTC 2026
_CudaDeviceProperties(name='NVIDIA H100 80GB HBM3', major=9, minor=0, total_memory=81089MB, multi_processor_count=132, uuid=7d93d577-7507-86a4-722f-07fdc4b6905e, L2_cache_size=50MB)
0 0

Applied default for experiment.goal: test
Applied default for experiment.device: cuda
Applied default for experiment.device_id: 0
Applied default for experiment.runs: 1
Applied default for experiment.seed: -1
Applied default for experiment.optimize_memory: False
Applied default for experiment.debug: False
Applied default for federation.join_ratio: 1.0
Applied default for federation.generate_images_frequency: 0
Applied default for model.num_classes: 10
Applied default for model.embedding_size: 768
Applied default for model.patch_size: 16
Applied default for training.momentum: 0.9
Applied default for training.learning_rate_schedule: False
Applied default for dataset.image_size: -1
Applied default for dataset.transform: False
Applied default for dataset.partition: pat
Applied default for dataset.dir_alpha: 0.1
Applied default for dataset.balance: False
Applied default for rewind.epochs: 0
Applied default for rewind.ratio: 0.0
Applied default for rewind.interval: 0
Applied default for rewind.strategy: none
Applied default for fedgfe.nodes_datasets: cifar10
Applied default for fedgfe.nodes_downstream_tasks: none
Applied default for fedgfe.nodes_pretext_tasks: 
Applied default for fedgfe.nodes_training_sequence: both
Applied default for fedgfe.cls_token_only: False
Applied default for fedgfe.limit_samples_number: 0
Applied default for feda2v.diffusion_type: sd
Applied default for feda2v.use_act_loss: False
Applied default for feda2v.use_text_loss: True
Applied default for feda2v.use_image_loss: False
Applied default for feda2v.audio_model_name: MIT/ast-finetuned-audioset-10-10-0.4593
Applied default for feda2v.image_model_name: google/vit-base-patch16-224-in21k
Applied default for feda2v.img_pipe_name: runwayml/stable-diffusion-v1-5
Applied default for feda2v.img_lcm_lora_id: latent-consistency/lcm-lora-sdv1-5
Applied default for feda2v.audio_pipe_name: cvssp/audioldm-l-full
Applied default for feda2v.steps: 1000
Applied default for feda2v.mode: train_nodata
Applied default for feda2v.ablation_type: only_t5
Applied default for feda2v.controllability_type: volume
Applied default for feda2v.target_img_path: data/img
Applied default for feda2v.img_out_path: exp/img
Applied default for feda2v.audio_out_path: exp/audio
Applied default for feda2v.class_to_activate: 8
Applied default for feda2v.single_class: False
Applied default for feda2v.checkpoint_name: best_model
Applied default for feda2v.project: sinestesia
Applied default for feda2v.entity: ctlab-team
Applied default for feda2v.wandb_mode: offline
Applied default for feda2v.global_model_train_from_generator: False
Applied default for feda2v.global_model_train_from_nodes_audio_embeddings: False
Applied default for feda2v.global_model_train_inputs: none
Applied default for feda2v.adapter_aggregation_method: none
Applied default for feda2v.text_losses_summed: False
Applied default for feda2v.compute_global_mean_from_class_means: False
Applied default for feda2v.generation_split_for_metrics: ['test', 'val']
Applied default for feda2v.synthetic_samples_per_class: auto
Applied default for feda2v.reset_generator_on_class_change: True
Applied default for feda2v.shared_generator_in_only_mode: True
Applied default for nodes.0.dataset_split: all
Applied default for nodes.0.pretext_tasks: []
Applied default for nodes.0.task_type: classification
Applied default for nodes.0.balance_classes: False
Applied default for nodes.0.use_folds: False
Applied default for nodes.0.train_folds: [0, 1, 2, 3]
Applied default for nodes.0.test_folds: [4]
Applied default for nodes.1.dataset_split: all
Applied default for nodes.1.pretext_tasks: []
Applied default for nodes.1.task_type: classification
Applied default for nodes.1.balance_classes: False
Applied default for nodes.1.use_folds: False
Applied default for nodes.1.train_folds: [0, 1, 2, 3]
Applied default for nodes.1.test_folds: [4]
Warning: Could not map class label 'dog' to numeric index
Node 0: Selected classes ['dog'] -> []
Warning: Could not map class label 'chainsaw' to numeric index
Node 1: Selected classes ['chainsaw'] -> []
Set num_clients: 2
Successfully loaded configuration from: configs/a2v_vegas_2n_2c_200s_train_adapters.json
Using nodes_tasks from config file (already processed)
==================================================
Algorithm: FedA2V
Local batch size: 8
Local epochs: 20
Local learing rate: 0.001
Local learing rate schedule: False
Total number of clients: 2
Clients join in each round: 1.0
Clients randomly join: False
Client drop rate: 0.0
Client select regarding time: False
Running times: 1
Dataset: VEGAS
Number of classes: 10
Backbone: a2v
Using device: cuda
Using DP: False
Auto break: False
Global rounds: 10
DLG attack: False
Total number of new clients: 0
Fine tuning epoches on new clients: 0
A2V G model sd

============= Running time: 0th =============
Creating server and clients ...
None
Enabling wandb to progect:  FedA2V
Finished creating server and clients.
2026-01-21 10:26:34,904 - utils.ballooning - INFO - Initialized GPUMemoryBalloon for GPU 0
2026-01-21 10:26:35,148 - utils.ballooning - INFO - GPU 0: Total memory: 81089 MB, Free before: 80563 MB, Target reserve: 0 MB
2026-01-21 10:26:35,149 - utils.ballooning - INFO - GPU 0: Successfully allocated 0 MB. Free memory: 80563 MB -> 80563 MB
2026-01-21 10:26:36,454 - flcore.trainmodel.downstreamsinestesiaadapters - INFO - Initializing AST model: MIT/ast-finetuned-audioset-10-10-0.4593
2026-01-21 10:26:37,015 - flcore.trainmodel.downstreamsinestesiaadapters - INFO - AST model initialized successfully
Started diffusion model flux
Creating 0 Audio2Visual node from nodes_tasks configuration:, using dataset VEGAS and labels ['dog']
2026-01-21 10:26:41,814 - datautils.dataset_vegas - INFO - Auto-creating train/val/test splits (split=None)
2026-01-21 10:26:41,814 - datautils.dataset_vegas - INFO - Creating train split...
2026-01-21 10:26:41,997 - datautils.dataset_vegas - INFO - Node split 0 - Class dog: 200 samples (requested: 200)
2026-01-21 10:26:41,998 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:42,173 - datautils.dataset_vegas - INFO - Node split 0 - Class dog: 200 samples (requested: 200)
2026-01-21 10:26:42,173 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:42,175 - datautils.dataset_vegas - INFO - VEGAS Dataset initialized: 180 samples, classes: ['dog'], split: train
2026-01-21 10:26:42,176 - datautils.dataset_vegas - INFO - Creating validation split...
2026-01-21 10:26:42,358 - datautils.dataset_vegas - INFO - Node split 0 - Class dog: 200 samples (requested: 200)
2026-01-21 10:26:42,359 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:42,533 - datautils.dataset_vegas - INFO - Node split 0 - Class dog: 200 samples (requested: 200)
2026-01-21 10:26:42,534 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:42,536 - datautils.dataset_vegas - INFO - VEGAS Dataset initialized: 20 samples, classes: ['dog'], split: val
2026-01-21 10:26:42,536 - datautils.dataset_vegas - INFO - Creating test split...
2026-01-21 10:26:42,719 - datautils.dataset_vegas - INFO - Node split 0 - Class dog: 200 samples (requested: 200)
2026-01-21 10:26:42,720 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:42,902 - datautils.dataset_vegas - INFO - Node split 0 - Class dog: 200 samples (requested: 200)
2026-01-21 10:26:42,902 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:42,904 - datautils.dataset_vegas - INFO - VEGAS Dataset initialized: 0 samples, classes: ['dog'], split: test
2026-01-21 10:26:42,904 - datautils.dataset_vegas - INFO - Auto-split created: train=180, val=20, test=0
2026-01-21 10:26:43,078 - datautils.dataset_vegas - INFO - Node split 0 - Class dog: 200 samples (requested: 200)
2026-01-21 10:26:43,078 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:43,254 - datautils.dataset_vegas - INFO - Node split 0 - Class dog: 200 samples (requested: 200)
2026-01-21 10:26:43,254 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:43,256 - datautils.dataset_vegas - INFO - VEGAS Dataset initialized: 200 samples, classes: ['dog'], split: None
Stratified split: train=180, val=20, test=0
Trying to set schdulers but no optimizer for client  0
2026-01-21 10:26:45,496 - flcore.clients.clientA2V - INFO - Node 0: Using global use_cls_token_only=False
2026-01-21 10:26:46,352 - flcore.trainmodel.downstreamsinestesiaadapters - INFO - ================================================================================
2026-01-21 10:26:46,353 - flcore.trainmodel.downstreamsinestesiaadapters - INFO - SKIPPING AST INITIALIZATION - Using pretrained generators mode or disabled by constructor
2026-01-21 10:26:46,353 - flcore.trainmodel.downstreamsinestesiaadapters - INFO - ================================================================================
Stratified split: train=180, val=20, test=0
[Client 0] Auto-calculated synthetic_samples_per_class = 180 (total samples: 180, classes: 1)
Creating 1 Audio2Visual node from nodes_tasks configuration:, using dataset VEGAS and labels ['chainsaw']
2026-01-21 10:26:50,673 - datautils.dataset_vegas - INFO - Auto-creating train/val/test splits (split=None)
2026-01-21 10:26:50,673 - datautils.dataset_vegas - INFO - Creating train split...
2026-01-21 10:26:50,799 - datautils.dataset_vegas - INFO - Node split 0 - Class chainsaw: 200 samples (requested: 200)
2026-01-21 10:26:50,800 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:50,918 - datautils.dataset_vegas - INFO - Node split 0 - Class chainsaw: 200 samples (requested: 200)
2026-01-21 10:26:50,919 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:50,921 - datautils.dataset_vegas - INFO - VEGAS Dataset initialized: 180 samples, classes: ['chainsaw'], split: train
2026-01-21 10:26:50,921 - datautils.dataset_vegas - INFO - Creating validation split...
2026-01-21 10:26:51,047 - datautils.dataset_vegas - INFO - Node split 0 - Class chainsaw: 200 samples (requested: 200)
2026-01-21 10:26:51,047 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:51,165 - datautils.dataset_vegas - INFO - Node split 0 - Class chainsaw: 200 samples (requested: 200)
2026-01-21 10:26:51,165 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:51,167 - datautils.dataset_vegas - INFO - VEGAS Dataset initialized: 20 samples, classes: ['chainsaw'], split: val
2026-01-21 10:26:51,167 - datautils.dataset_vegas - INFO - Creating test split...
2026-01-21 10:26:51,292 - datautils.dataset_vegas - INFO - Node split 0 - Class chainsaw: 200 samples (requested: 200)
2026-01-21 10:26:51,293 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:51,410 - datautils.dataset_vegas - INFO - Node split 0 - Class chainsaw: 200 samples (requested: 200)
2026-01-21 10:26:51,410 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:51,411 - datautils.dataset_vegas - INFO - VEGAS Dataset initialized: 0 samples, classes: ['chainsaw'], split: test
2026-01-21 10:26:51,411 - datautils.dataset_vegas - INFO - Auto-split created: train=180, val=20, test=0
2026-01-21 10:26:51,526 - datautils.dataset_vegas - INFO - Node split 0 - Class chainsaw: 200 samples (requested: 200)
2026-01-21 10:26:51,526 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:51,642 - datautils.dataset_vegas - INFO - Node split 0 - Class chainsaw: 200 samples (requested: 200)
2026-01-21 10:26:51,642 - datautils.dataset_vegas - INFO - Node split 0 total samples after split: 200
2026-01-21 10:26:51,643 - datautils.dataset_vegas - INFO - VEGAS Dataset initialized: 200 samples, classes: ['chainsaw'], split: None
Stratified split: train=180, val=20, test=0
Trying to set schdulers but no optimizer for client  1
2026-01-21 10:26:53,865 - flcore.clients.clientA2V - INFO - Node 1: Using global use_cls_token_only=False
2026-01-21 10:26:54,770 - flcore.trainmodel.downstreamsinestesiaadapters - INFO - ================================================================================
2026-01-21 10:26:54,771 - flcore.trainmodel.downstreamsinestesiaadapters - INFO - SKIPPING AST INITIALIZATION - Using pretrained generators mode or disabled by constructor
2026-01-21 10:26:54,771 - flcore.trainmodel.downstreamsinestesiaadapters - INFO - ================================================================================
Stratified split: train=180, val=20, test=0
[Client 1] Auto-calculated synthetic_samples_per_class = 180 (total samples: 180, classes: 1)
Created server test dataset with 0 samples from 2 nodes
2026-01-21 10:26:59,129 - flcore.servers.serverA2V - INFO - [Server] Auto-calculating synthetic_samples_per_class for each node and class
2026-01-21 10:26:59,130 - flcore.servers.serverA2V - INFO - [Server] Node 0: 180 synthetic samples/class (total samples: 180, classes: 1)
2026-01-21 10:26:59,130 - flcore.servers.serverA2V - INFO - [Server] Node 1: 180 synthetic samples/class (total samples: 180, classes: 1)
2026-01-21 10:26:59,130 - flcore.servers.serverA2V - INFO - [Server] Average synthetic_samples_per_class = 180

*** Client 0 dataset VEGAS
2026-01-21 10:26:59,130 - flcore.servers.serverA2V - WARNING - Skipping dataset details for VEGASDataset to avoid long logs.

*** Client 1 dataset VEGAS
2026-01-21 10:26:59,130 - flcore.servers.serverA2V - WARNING - Skipping dataset details for VEGASDataset to avoid long logs.
2026-01-21 10:26:59,132 - flcore.servers.serverA2V - INFO - Finished creating Audio2Visual server and clients.

-------------Round number: 1-------------

Evaluate Audio2Visual models
[Server] Skipping test_metrics: adapters not being trained (train_adapters=False)
[Server] Skipping train_metrics: adapters not being trained (train_adapters=False)
2026-01-21 10:26:59,404 - flcore.servers.serverA2V - WARNING - === Round 1 starting hook temporally disabled ===
Creating dataloader for train dataset for client 0 with 180 samples
Creating dataloader for test dataset for client 0 with 0 samples
Creating optimizer for node 0 with model optimizer AdamW and learning rate 0.001
Creating learning rate scheduler for node 0
Node 0: No optimizer initialized
Node 0 training Audio2Visual model for 20 epochs
Node 0 - Computing mean adapter outputs per class from training data
Node 0 - Stored outputs for 0 classes, 0 adapters, 0 total samples

====================================================================================================
[Node 0] âš ï¸  MEMORY GROWTH DETECTED - Round 1
====================================================================================================

ğŸ“Š MEMORY SUMMARY:
  Start:  Allocated=3.89 GB, Reserved=4.03 GB (5.1%)
  End:    Allocated=6.70 GB, Reserved=7.99 GB (10.1%)
  Growth: Allocated=+2.817 GB, Reserved=+3.959 GB

ğŸ“ˆ PER-EPOCH BREAKDOWN:
Epoch    Allocated (GB)       Reserved (GB)        Î” Alloc         Î” Reserved      Avg Loss    
-------- -------------------- -------------------- --------------- --------------- ------------
1          6.70 GB            7.99 GB          +2.816 GB     +3.959 GB     0.8215
2          6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.2016
3          6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0364
4          6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0120
5          6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0104
6          6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0094
7          6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0090
8          6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0087
9          6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0085
10         6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0085
11         6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0084
12         6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0084
13         6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0084
14         6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0084
15         6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0084
16         6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0084
17         6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0084
18         6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0084
19         6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0084
20         6.70 GB            7.99 GB          +2.817 GB     +3.959 GB     0.0084

  ğŸ”´ Max growth at Epoch 1: +3.959 GB reserved
====================================================================================================


Generating images for Node 0 using Audio2Visual model.
Generating images for split: val
Node 0 - Processing 3 batches from dataset...
  Progress: 3/3 batches processed, 20 total samples
Node 0 - âœ“ Retrieved 20 audio embeddings from dataset
Node 0 - Embedding shapes: clip: torch.Size([20, 768]), t5: torch.Size([20, 17, 4096])
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_0.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_1.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_2.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_3.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_4.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_5.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_6.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_7.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_8.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_9.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_10.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_11.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_12.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_13.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_14.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_15.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_16.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_17.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_18.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_19.png
âœ“ Cleaned up memory after val split
Creating dataloader for train dataset for client 1 with 180 samples
Creating dataloader for test dataset for client 1 with 0 samples
Creating optimizer for node 1 with model optimizer AdamW and learning rate 0.001
Creating learning rate scheduler for node 1
Node 1: No optimizer initialized
Node 1 training Audio2Visual model for 20 epochs
Node 1 - Computing mean adapter outputs per class from training data
Node 1 - Stored outputs for 0 classes, 0 adapters, 0 total samples

====================================================================================================
[Node 1] âš ï¸  MEMORY GROWTH DETECTED - Round 1
====================================================================================================

ğŸ“Š MEMORY SUMMARY:
  Start:  Allocated=3.39 GB, Reserved=3.48 GB (4.4%)
  End:    Allocated=6.14 GB, Reserved=7.22 GB (9.1%)
  Growth: Allocated=+2.754 GB, Reserved=+3.748 GB

ğŸ“ˆ PER-EPOCH BREAKDOWN:
Epoch    Allocated (GB)       Reserved (GB)        Î” Alloc         Î” Reserved      Avg Loss    
-------- -------------------- -------------------- --------------- --------------- ------------
1          6.14 GB            6.87 GB          +2.755 GB     +3.396 GB     0.8466
2          6.14 GB            7.22 GB          +2.755 GB     +3.748 GB     0.2125
3          6.14 GB            7.12 GB          +2.754 GB     +3.646 GB     0.0407
4          6.14 GB            7.22 GB          +2.754 GB     +3.748 GB     0.0137
5          6.14 GB            7.12 GB          +2.754 GB     +3.646 GB     0.0116
6          6.14 GB            7.22 GB          +2.754 GB     +3.748 GB     0.0107
7          6.14 GB            7.12 GB          +2.754 GB     +3.646 GB     0.0101
8          6.14 GB            7.22 GB          +2.754 GB     +3.748 GB     0.0098
9          6.14 GB            7.12 GB          +2.754 GB     +3.646 GB     0.0097
10         6.14 GB            7.22 GB          +2.754 GB     +3.748 GB     0.0096
11         6.14 GB            7.12 GB          +2.754 GB     +3.646 GB     0.0096
12         6.14 GB            7.22 GB          +2.754 GB     +3.748 GB     0.0095
13         6.14 GB            7.12 GB          +2.754 GB     +3.646 GB     0.0095
14         6.14 GB            7.22 GB          +2.754 GB     +3.748 GB     0.0095
15         6.14 GB            7.12 GB          +2.754 GB     +3.646 GB     0.0095
16         6.14 GB            7.22 GB          +2.754 GB     +3.748 GB     0.0095
17         6.14 GB            7.12 GB          +2.754 GB     +3.646 GB     0.0095
18         6.14 GB            7.22 GB          +2.754 GB     +3.748 GB     0.0094
19         6.14 GB            7.12 GB          +2.754 GB     +3.646 GB     0.0094
20         6.14 GB            7.22 GB          +2.754 GB     +3.748 GB     0.0094

  ğŸ”´ Max growth at Epoch 2: +3.748 GB reserved
====================================================================================================


Generating images for Node 1 using Audio2Visual model.
Generating images for split: val
Node 1 - Processing 3 batches from dataset...
  Progress: 3/3 batches processed, 20 total samples
Node 1 - âœ“ Retrieved 20 audio embeddings from dataset
Node 1 - Embedding shapes: clip: torch.Size([20, 768]), t5: torch.Size([20, 17, 4096])
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_0.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_1.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_2.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_3.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_4.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_5.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_6.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_7.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_8.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_9.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_10.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_11.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_12.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_13.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_14.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_15.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_16.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_17.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_18.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_19.png
âœ“ Cleaned up memory after val split
[]
--------------------------------------------------Round 1 time:  333.2932426929474
2026-01-21 10:32:32,697 - utils.ballooning - INFO - GPU 0: No memory to release
Node 0 metrics: train on train text_loss 0.0042
Client 0: Generating images from split 'val' for metrics computation

Client 0: Generating images from val split using server's diffusion model
Node 0 - Processing 3 batches from dataset...
  Progress: 3/3 batches processed, 20 total samples
Node 0 - âœ“ Retrieved 20 audio embeddings from dataset
Node 0 - Embedding shapes: clip: torch.Size([20, 768]), t5: torch.Size([20, 17, 4096])
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_0.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_1.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_2.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_3.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_4.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_5.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_6.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_7.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_8.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_9.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_10.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_11.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_12.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_13.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_14.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_15.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_16.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_17.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_18.png
Client 0: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_19.png
Client 0: Generated 20 images from val split
task accuracy: 0.20 (std: 0.00, min: 0.20 at index 0, max: 0.200000 at index 0)
task balanced_accuracy: 0.20 (std: 0.00, min: 0.20 at index 0, max: 0.200000 at index 0)
task f1_score: 0.05 (std: 0.00, min: 0.05 at index 0, max: 0.047619 at index 0)
task precision: 0.14 (std: 0.00, min: 0.14 at index 0, max: 0.142857 at index 0)
task recall: 0.03 (std: 0.00, min: 0.03 at index 0, max: 0.028571 at index 0)
task f1_score_weighted: 0.33 (std: 0.00, min: 0.33 at index 0, max: 0.333333 at index 0)

Node 0 metrics: test on val accuracy 0.2000

Generating images for Node 0 using Audio2Visual model.
Generating images for split: val
Node 0 - Processing 3 batches from dataset...
  Progress: 3/3 batches processed, 20 total samples
Node 0 - âœ“ Retrieved 20 audio embeddings from dataset
Node 0 - Embedding shapes: clip: torch.Size([20, 768]), t5: torch.Size([20, 17, 4096])
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_0.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_1.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_2.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_3.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_4.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_5.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_6.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_7.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_8.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_9.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_10.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_11.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_12.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_13.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_14.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_15.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_16.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_17.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_18.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_0_20le_10gr_dog_val_19.png
âœ“ Cleaned up memory after val split
Node 1 metrics: train on train text_loss 0.0048
Client 1: Generating images from split 'val' for metrics computation

Client 1: Generating images from val split using server's diffusion model
Node 1 - Processing 3 batches from dataset...
  Progress: 3/3 batches processed, 20 total samples
Node 1 - âœ“ Retrieved 20 audio embeddings from dataset
Node 1 - Embedding shapes: clip: torch.Size([20, 768]), t5: torch.Size([20, 17, 4096])
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_0.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_1.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_2.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_3.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_4.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_5.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_6.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_7.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_8.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_9.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_10.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_11.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_12.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_13.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_14.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_15.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_16.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_17.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_18.png
Client 1: Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_19.png
Client 1: Generated 20 images from val split
task accuracy: 0.90 (std: 0.00, min: 0.90 at index 0, max: 0.900000 at index 0)
task balanced_accuracy: 0.90 (std: 0.00, min: 0.90 at index 0, max: 0.900000 at index 0)
task f1_score: 0.32 (std: 0.00, min: 0.32 at index 0, max: 0.315789 at index 0)
task precision: 0.33 (std: 0.00, min: 0.33 at index 0, max: 0.333333 at index 0)
task recall: 0.30 (std: 0.00, min: 0.30 at index 0, max: 0.300000 at index 0)
task f1_score_weighted: 0.95 (std: 0.00, min: 0.95 at index 0, max: 0.947368 at index 0)

Node 1 metrics: test on val accuracy 0.9000

Generating images for Node 1 using Audio2Visual model.
Generating images for split: val
Node 1 - Processing 3 batches from dataset...
  Progress: 3/3 batches processed, 20 total samples
Node 1 - âœ“ Retrieved 20 audio embeddings from dataset
Node 1 - Embedding shapes: clip: torch.Size([20, 768]), t5: torch.Size([20, 17, 4096])
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_0.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_1.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_2.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_3.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_4.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_5.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_6.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_7.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_8.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_9.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_10.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_11.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_12.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_13.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_14.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_15.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_16.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_17.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_18.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_1_node_1_20le_10gr_chainsaw_val_19.png
âœ“ Cleaned up memory after val split
2026-01-21 10:34:29,785 - utils.ballooning - INFO - GPU 0: Balloon already inflated, skipping
Generated images for split val: 20 samples.
task accuracy: 0.25 (std: 0.00, min: 0.25 at index 0, max: 0.250000 at index 0)
task balanced_accuracy: 0.25 (std: 0.00, min: 0.25 at index 0, max: 0.250000 at index 0)
task f1_score: 0.06 (std: 0.00, min: 0.06 at index 0, max: 0.057143 at index 0)
task precision: 0.14 (std: 0.00, min: 0.14 at index 0, max: 0.142857 at index 0)
task recall: 0.04 (std: 0.00, min: 0.04 at index 0, max: 0.035714 at index 0)
task f1_score_weighted: 0.40 (std: 0.00, min: 0.40 at index 0, max: 0.400000 at index 0)

Node 0
{'val': NodeMetric([], {'samples': 0, 'steps': 0, 0: NodeMetric([], {'samples': 0, 'steps': 0, 'accuracy': 0.25, 'balanced_accuracy': 0.25, 'f1_score': 0.05714285714285715, 'precision': 0.14285714285714285, 'recall': 0.03571428571428571, 'f1_score_weighted': 0.4}), 'accuracy': {'mean': 0.25, 'std': 0.0, 'min': 0.25, 'max': 0.25, 'min_index': 0, 'max_index': 0}, 'balanced_accuracy': {'mean': 0.25, 'std': 0.0, 'min': 0.25, 'max': 0.25, 'min_index': 0, 'max_index': 0}, 'f1_score': {'mean': 0.05714285714285715, 'std': 0.0, 'min': 0.05714285714285715, 'max': 0.05714285714285715, 'min_index': 0, 'max_index': 0}, 'precision': {'mean': 0.14285714285714285, 'std': 0.0, 'min': 0.14285714285714285, 'max': 0.14285714285714285, 'min_index': 0, 'max_index': 0}, 'recall': {'mean': 0.03571428571428571, 'std': 0.0, 'min': 0.03571428571428571, 'max': 0.03571428571428571, 'min_index': 0, 'max_index': 0}, 'f1_score_weighted': {'mean': 0.4, 'std': 0.0, 'min': 0.4, 'max': 0.4, 'min_index': 0, 'max_index': 0}})}
Generated images for split val: 20 samples.
task accuracy: 0.90 (std: 0.00, min: 0.90 at index 0, max: 0.900000 at index 0)
task balanced_accuracy: 0.90 (std: 0.00, min: 0.90 at index 0, max: 0.900000 at index 0)
task f1_score: 0.32 (std: 0.00, min: 0.32 at index 0, max: 0.315789 at index 0)
task precision: 0.33 (std: 0.00, min: 0.33 at index 0, max: 0.333333 at index 0)
task recall: 0.30 (std: 0.00, min: 0.30 at index 0, max: 0.300000 at index 0)
task f1_score_weighted: 0.95 (std: 0.00, min: 0.95 at index 0, max: 0.947368 at index 0)

Node 1
{'val': NodeMetric([], {'samples': 0, 'steps': 0, 0: NodeMetric([], {'samples': 0, 'steps': 0, 'accuracy': 0.9, 'balanced_accuracy': 0.9, 'f1_score': 0.3157894736842105, 'precision': 0.3333333333333333, 'recall': 0.3, 'f1_score_weighted': 0.9473684210526315}), 'accuracy': {'mean': 0.9, 'std': 0.0, 'min': 0.9, 'max': 0.9, 'min_index': 0, 'max_index': 0}, 'balanced_accuracy': {'mean': 0.9, 'std': 0.0, 'min': 0.9, 'max': 0.9, 'min_index': 0, 'max_index': 0}, 'f1_score': {'mean': 0.3157894736842105, 'std': 0.0, 'min': 0.3157894736842105, 'max': 0.3157894736842105, 'min_index': 0, 'max_index': 0}, 'precision': {'mean': 0.3333333333333333, 'std': 0.0, 'min': 0.3333333333333333, 'max': 0.3333333333333333, 'min_index': 0, 'max_index': 0}, 'recall': {'mean': 0.3, 'std': 0.0, 'min': 0.3, 'max': 0.3, 'min_index': 0, 'max_index': 0}, 'f1_score_weighted': {'mean': 0.9473684210526315, 'std': 0.0, 'min': 0.9473684210526315, 'max': 0.9473684210526315, 'min_index': 0, 'max_index': 0}})}

-------------Round number: 2-------------

Evaluate Audio2Visual models
[Server] Skipping test_metrics: adapters not being trained (train_adapters=False)
[Server] Skipping train_metrics: adapters not being trained (train_adapters=False)
2026-01-21 10:35:00,668 - flcore.servers.serverA2V - WARNING - === Round 2 starting hook temporally disabled ===
Node 0 training Audio2Visual model for 20 epochs
Node 0 - Computing mean adapter outputs per class from training data
Node 0 - Stored outputs for 0 classes, 0 adapters, 0 total samples

Generating images for Node 0 using Audio2Visual model.
Generating images for split: val
Node 0 - Processing 3 batches from dataset...
  Progress: 3/3 batches processed, 20 total samples
Node 0 - âœ“ Retrieved 20 audio embeddings from dataset
Node 0 - Embedding shapes: clip: torch.Size([20, 768]), t5: torch.Size([20, 17, 4096])
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_0.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_1.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_2.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_3.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_4.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_5.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_6.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_7.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_8.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_9.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_10.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_11.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_12.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_13.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_14.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_15.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_16.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_17.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_18.png
Saved generated image to output_images/vegas-2n-2c-200s-train-adapters/round_2_node_0_20le_10gr_dog_val_19.png
âœ“ Cleaned up memory after val split
Node 1 training Audio2Visual model for 20 epochs
