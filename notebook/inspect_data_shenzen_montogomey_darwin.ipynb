{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cuda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m datasets_dirs \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDarwin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMontgomery\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShenzhen\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;129;01min\u001b[39;00m datasets_dirs]\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     20\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cuda' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "pwd = os.getcwd()\n",
    "dataset_path = '../dataset'\n",
    "data_path = dataset_path + '/ChestXRaySegmentation'\n",
    "datasets_dirs = [ 'Darwin', 'Montgomery', 'Shenzhen']\n",
    "datasets = [data_path + '/' + dir for dir in datasets_dirs]\n",
    "\n",
    "if cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "\n",
    "\n",
    "def grid_show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    plt.show()\n",
    "\n",
    "def plot_image(image_sample):\n",
    "    plt.imshow(image_sample, cmap='gray')  # Puoi cambiare 'gray' se l'immagine Ã¨ a colori\n",
    "    plt.axis('off')  # Rimuovi gli assi per una visualizzazione pulita\n",
    "    plt.show()\n",
    "\n",
    "def plot_grid_images(images, nrow=1):\n",
    "    # for i in range(len(images)):\n",
    "    #     images[i] = images[i].permute(2, 0, 1)\n",
    "            \n",
    "    grid = make_grid(images, nrow=nrow)\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    plot_image(grid)\n",
    "\n",
    "def read_image_as_tensor(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image_tensor = F.to_tensor(image)\n",
    "    return image_tensor\n",
    "\n",
    "def downsample_image(image_tensor, h, w):\n",
    "    image_tensor = F.resize(image_tensor, (h, w))\n",
    "    return image_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image torch.Size([3, 512, 512]) mask torch.Size([1, 512, 512])\n",
      "Image torch.Size([3, 224, 224]) mask torch.Size([1, 224, 224])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 224, 224] at entry 0 and [1, 224, 224] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     downsampled_mask \u001b[38;5;241m=\u001b[39m downsample_image(mask_tensor, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m ( \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m mask \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m(\u001b[38;5;28mstr\u001b[39m(downsampled_image\u001b[38;5;241m.\u001b[39mshape), \u001b[38;5;28mstr\u001b[39m(downsampled_mask\u001b[38;5;241m.\u001b[39mshape)))\n\u001b[0;32m---> 22\u001b[0m     plot_grid_images([downsampled_image, downsampled_mask], nrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo mask for sample \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39msample_file)\n",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m, in \u001b[0;36mplot_grid_images\u001b[0;34m(images, nrow)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_grid_images\u001b[39m(images, nrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# for i in range(len(images)):\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m#     images[i] = images[i].permute(2, 0, 1)\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     grid \u001b[38;5;241m=\u001b[39m make_grid(images, nrow\u001b[38;5;241m=\u001b[39mnrow)\n\u001b[1;32m     42\u001b[0m     grid \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     43\u001b[0m     plot_image(grid)\n",
      "File \u001b[0;32m~/miniconda3/envs/flvit/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/flvit/lib/python3.12/site-packages/torchvision/utils.py:67\u001b[0m, in \u001b[0;36mmake_grid\u001b[0;34m(tensor, nrow, padding, normalize, value_range, scale_each, pad_value)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# if list of tensors, convert to a 4D mini-batch Tensor\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(tensor, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:  \u001b[38;5;66;03m# single image H x W\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 224, 224] at entry 0 and [1, 224, 224] at entry 1"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "labels = []\n",
    "samples = torch.tensor([])\n",
    "sam = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    sample_dir = Path(dataset+'/img')\n",
    "    mask_dir = Path(dataset+'/mask')\n",
    "\n",
    "    for sample_file in sample_dir.iterdir():\n",
    "        if sample_file.suffix == '.png':\n",
    "            mask_file = mask_dir / (sample_file.stem + '.png')\n",
    "            if mask_file.exists():\n",
    "                image_tensor = read_image_as_tensor(sample_file)\n",
    "                mask_tensor = read_image_as_tensor(mask_file)\n",
    "                print ( \"Image %s mask %s\" %(str(image_tensor.shape), str(mask_tensor.shape)))\n",
    "                downsampled_image = downsample_image(image_tensor, 224, 224)\n",
    "                downsampled_mask = downsample_image(mask_tensor, 224, 224)\n",
    "                print ( \"Image %s mask %s\" %(str(downsampled_image.shape), str(downsampled_mask.shape)))\n",
    "\n",
    "                plot_grid_images([downsampled_image, downsampled_mask], nrow=2)\n",
    "            else:\n",
    "                print('No mask for sample %s' %sample_file)\n",
    "\n",
    "        \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
