{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VEGAS Dataset - Node Splits Testing\n",
    "\n",
    "Questo notebook testa le funzionalit√† di splitting del dataset VEGAS:\n",
    "- Split per nodo con singola classe\n",
    "- Split per nodo con pi√π classi\n",
    "- Visualizzazione immagini\n",
    "- Riproduzione audio\n",
    "- Verifica bilanciamento dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup e Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\n\n# Set working directory to project root\nproject_root = Path.home() / 'fedgfe'\nos.chdir(project_root)\nprint(f\"Working directory set to: {os.getcwd()}\\n\")\n\nimport sys\nsys.path.append('system')\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport IPython.display as ipd\nimport json\n\nfrom datautils.dataset_vegas import VEGASDataset\n\nprint(\"‚úì Imports completed\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì VEGAS dataset found at: dataset/Audio/VEGAS\n"
     ]
    }
   ],
   "source": [
    "# Path al dataset VEGAS (relativo alla working directory)\n",
    "VEGAS_ROOT = Path(\"dataset/Audio/VEGAS\")\n",
    "\n",
    "# Verifica esistenza\n",
    "if not VEGAS_ROOT.exists():\n",
    "    print(f\"‚ö†Ô∏è  VEGAS dataset not found at: {VEGAS_ROOT}\")\n",
    "    print(\"Please update the path or download the dataset\")\n",
    "else:\n",
    "    print(f\"‚úì VEGAS dataset found at: {VEGAS_ROOT}\")\n",
    "    \n",
    "# Configurazione\n",
    "config = {\n",
    "    'dataset_path': str(VEGAS_ROOT),\n",
    "    'audio_sample_rate': 16000,\n",
    "    'audio_duration': 10.0,\n",
    "    'image_size': (224, 224),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Esplora Dataset VEGAS Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available classes in VEGAS dataset:\n",
      "\n",
      "Total classes: 10\n",
      "\n",
      "Class labels:\n",
      "  0: baby_cry\n",
      "  1: chainsaw\n",
      "  2: dog\n",
      "  3: drum\n",
      "  4: fireworks\n",
      "  5: helicopter\n",
      "  6: printer\n",
      "  7: rail_transport\n",
      "  8: snoring\n",
      "  9: water_flowing\n",
      "\n",
      "================================================================================\n",
      "Loading dataset (this may take a moment)...\n",
      "================================================================================\n",
      "\n",
      "‚úì Dataset loaded successfully!\n",
      "Total samples in VEGAS train split: 19674\n",
      "\n",
      "Sampling first 100 samples to check class distribution...\n",
      "\n",
      "Class distribution (first 100 samples):\n",
      "  printer                       :   15 samples\n",
      "  water_flowing                 :   15 samples\n",
      "  rail_transport                :   15 samples\n",
      "  dog                           :   14 samples\n",
      "  fireworks                     :   13 samples\n",
      "  helicopter                    :    8 samples\n",
      "  drum                          :    7 samples\n",
      "  chainsaw                      :    6 samples\n",
      "  baby_cry                      :    4 samples\n",
      "  snoring                       :    3 samples\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi √® verificato un arresto anomalo del Kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. \n",
      "\u001b[1;31mEsaminare il codice nelle celle per identificare una possibile causa dell'errore. \n",
      "\u001b[1;31mPer altre informazioni, fare clic<a href='https://aka.ms/vscodeJupyterKernelCrash'>qui</a>. \n",
      "\u001b[1;31mPer ulteriori dettagli, visualizzare Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# Mostra le classi disponibili in VEGAS usando i metadati del dataset\n",
    "print(f\"Available classes in VEGAS dataset:\")\n",
    "print(f\"\\nTotal classes: {len(VEGASDataset.CLASS_LABELS)}\")\n",
    "print(\"\\nClass labels:\")\n",
    "for class_name, label in sorted(VEGASDataset.CLASS_LABELS.items(), key=lambda x: x[1]):\n",
    "    print(f\"  {label}: {class_name}\")\n",
    "\n",
    "# Carica solo un sample per verificare che il dataset funzioni\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Loading dataset (this may take a moment)...\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "full_dataset = VEGASDataset(\n",
    "    root_dir=str(VEGAS_ROOT),\n",
    "    split='train',\n",
    "    enable_ast_cache=False,\n",
    "    load_audio=True,\n",
    "    load_image=True,\n",
    "    load_video=False\n",
    ")\n",
    "\n",
    "print(f\"‚úì Dataset loaded successfully!\")\n",
    "print(f\"Total samples in VEGAS train split: {len(full_dataset)}\")\n",
    "\n",
    "# Conta samples per classe (solo i primi 100 per velocit√†)\n",
    "print(f\"\\nSampling first 100 samples to check class distribution...\")\n",
    "class_counts = {}\n",
    "sample_limit = min(100, len(full_dataset))\n",
    "\n",
    "for idx in range(sample_limit):\n",
    "    sample = full_dataset[idx]\n",
    "    class_name = sample.get('class_name', 'unknown')\n",
    "    class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "\n",
    "sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(f\"\\nClass distribution (first {sample_limit} samples):\")\n",
    "for class_name, count in sorted_classes:\n",
    "    print(f\"  {class_name:30s}: {count:4d} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Split Singola Classe per Nodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\nprint(\"TEST 1: Single Class per Node\")\nprint(\"=\" * 80)\n\n# Test con singola classe per nodo (ridotto a campioni pi√π piccoli)\nsingle_class_datasets = []\n\n# Node 0: solo 'dog' - RIDOTTO A 20 SAMPLES\nprint(f\"\\nNode 0: Loading 'dog' class (20 samples, split_id=0)...\")\nnode_0 = VEGASDataset(\n    root_dir=str(VEGAS_ROOT),\n    selected_classes=['dog'],\n    samples_per_node=20,  # RIDOTTO\n    node_split_id=0,\n    train_ratio=1.0,  # Tutto in train per semplificare\n    val_ratio=0.0,\n    test_ratio=0.0,\n    split='train',\n    enable_ast_cache=False,\n    load_audio=True,\n    load_image=True,\n    load_video=False\n)\nsingle_class_datasets.append(('dog', node_0))\nprint(f\"  ‚úì Loaded {len(node_0)} samples\")\n\n# Node 1: solo 'chainsaw' - RIDOTTO A 20 SAMPLES\nprint(f\"\\nNode 1: Loading 'chainsaw' class (20 samples, split_id=0)...\")\nnode_1 = VEGASDataset(\n    root_dir=str(VEGAS_ROOT),\n    selected_classes=['chainsaw'],\n    samples_per_node=20,  # RIDOTTO\n    node_split_id=0,\n    train_ratio=1.0,\n    val_ratio=0.0,\n    test_ratio=0.0,\n    split='train',\n    enable_ast_cache=False,\n    load_audio=True,\n    load_image=True,\n    load_video=False\n)\nsingle_class_datasets.append(('chainsaw', node_1))\nprint(f\"  ‚úì Loaded {len(node_1)} samples\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(f\"‚úì Created {len(single_class_datasets)} single-class datasets\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Split Multi-Classe per Nodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\nprint(\"TEST 2: Multiple Classes per Node\")\nprint(\"=\" * 80)\n\n# Test con pi√π classi per nodo (RIDOTTO)\nmulti_class_datasets = []\n\n# Node 0: dog, baby_cry, drum - RIDOTTO A 30 SAMPLES TOTALI\nprint(f\"\\nNode 0: Loading ['dog', 'baby_cry', 'drum'] (30 samples total)...\")\nmulti_node_0 = VEGASDataset(\n    root_dir=str(VEGAS_ROOT),\n    selected_classes=['dog', 'baby_cry', 'drum'],\n    samples_per_node=30,  # RIDOTTO\n    node_split_id=0,\n    train_ratio=1.0,\n    val_ratio=0.0,\n    test_ratio=0.0,\n    split='train',\n    enable_ast_cache=False,\n    load_audio=True,\n    load_image=True,\n    load_video=False\n)\nmulti_class_datasets.append((['dog', 'baby_cry', 'drum'], multi_node_0))\nprint(f\"  ‚úì Loaded {len(multi_node_0)} samples\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(f\"‚úì Created {len(multi_class_datasets)} multi-class dataset\")\nprint(\"=\" * 80)\n\n# Conta samples per classe\nfor i, (classes, dataset) in enumerate(multi_class_datasets):\n    print(f\"\\nMulti-Class Node {i} - Class distribution:\")\n    class_counts = {}\n    for idx in range(len(dataset)):\n        sample = dataset[idx]\n        class_name = sample.get('class_name', 'unknown')\n        class_counts[class_name] = class_counts.get(class_name, 0) + 1\n    \n    for cls in classes:\n        count = class_counts.get(cls, 0)\n        print(f\"  {cls:20s}: {count:3d} samples\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizzazione: Immagine + Audio\n",
    "\n",
    "Funzione helper per visualizzare un sample con immagine e audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def visualize_sample(sample, title=\"Sample\", show_audio=True):\n    \"\"\"\n    Visualizza un sample VEGAS: immagine + audio\n    \n    Args:\n        sample: dict con 'image', 'audio', 'class_name', etc.\n        title: titolo per il plot\n        show_audio: se True, mostra anche il waveform e player audio\n    \"\"\"\n    fig = plt.figure(figsize=(15, 8))\n    \n    # Info\n    class_name = sample.get('class_name', 'Unknown')\n    sample_id = sample.get('sample_id', 'N/A')\n    \n    # Layout: 2 righe, 2 colonne\n    # Row 1: Immagine (col 1-2)\n    # Row 2: Waveform (col 1), Spectrogram (col 2)\n    \n    # 1. Immagine\n    ax1 = plt.subplot(2, 2, (1, 2))\n    image = sample['image']\n    \n    # Convert tensor to numpy if needed (move to CPU first!)\n    if isinstance(image, torch.Tensor):\n        # [C, H, W] -> [H, W, C] and move to CPU\n        image = image.cpu().permute(1, 2, 0).numpy()\n    \n    # Denormalize se necessario\n    if image.min() < 0:\n        image = (image - image.min()) / (image.max() - image.min())\n    \n    ax1.imshow(image)\n    ax1.set_title(f\"{title}\\nClass: {class_name} | ID: {sample_id}\", fontsize=14, fontweight='bold')\n    ax1.axis('off')\n    \n    if show_audio and 'audio' in sample:\n        audio = sample['audio']\n        sample_rate = sample.get('sample_rate', 16000)\n        \n        # Convert tensor to numpy (move to CPU first!)\n        if isinstance(audio, torch.Tensor):\n            audio = audio.cpu().numpy()\n        \n        # 2. Waveform\n        ax2 = plt.subplot(2, 2, 3)\n        time_axis = np.arange(len(audio)) / sample_rate\n        ax2.plot(time_axis, audio, linewidth=0.5)\n        ax2.set_title(\"Audio Waveform\")\n        ax2.set_xlabel(\"Time (s)\")\n        ax2.set_ylabel(\"Amplitude\")\n        ax2.grid(True, alpha=0.3)\n        \n        # 3. Spectrogram\n        ax3 = plt.subplot(2, 2, 4)\n        ax3.specgram(audio, Fs=sample_rate, cmap='viridis')\n        ax3.set_title(\"Spectrogram\")\n        ax3.set_xlabel(\"Time (s)\")\n        ax3.set_ylabel(\"Frequency (Hz)\")\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Audio player\n    if show_audio and 'audio' in sample:\n        print(f\"\\nüîä Audio Player for: {class_name}\")\n        display(ipd.Audio(audio, rate=sample_rate))\n\nprint(\"‚úì Visualization function defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizza Samples da Nodo Single-Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\nprint(\"VISUALIZING SAMPLES FROM SINGLE-CLASS NODES\")\nprint(\"=\" * 80)\n\n# Visualizza 1 sample da ogni nodo single-class\nfor class_name, dataset in single_class_datasets:\n    print(f\"\\n{'='*80}\")\n    print(f\"Class: {class_name} ({len(dataset)} samples)\")\n    print(f\"{'='*80}\\n\")\n    \n    if len(dataset) > 0:\n        # Prendi un sample random\n        idx = np.random.randint(0, len(dataset))\n        sample = dataset[idx]\n        \n        visualize_sample(\n            sample, \n            title=f\"Class: {class_name} - Sample {idx}\",\n            show_audio=True\n        )\n    else:\n        print(f\"‚ö†Ô∏è  No samples in dataset\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizza Samples da Nodo Multi-Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\nprint(\"VISUALIZING SAMPLES FROM MULTI-CLASS NODES\")\nprint(\"=\" * 80)\n\n# Visualizza samples da nodi multi-class\nfor i, (classes, dataset) in enumerate(multi_class_datasets):\n    print(f\"\\n{'='*80}\")\n    print(f\"Multi-Class Node {i}: Classes {classes}\")\n    print(f\"{'='*80}\\n\")\n    \n    # Trova samples di classi diverse\n    shown_classes = set()\n    samples_to_show = min(3, len(classes))  # Max 3 per nodo\n    \n    attempts = 0\n    while len(shown_classes) < samples_to_show and attempts < 100:\n        idx = np.random.randint(0, len(dataset))\n        sample = dataset[idx]\n        class_name = sample.get('class_name', 'unknown')\n        \n        if class_name not in shown_classes:\n            shown_classes.add(class_name)\n            visualize_sample(\n                sample,\n                title=f\"Multi-Class Node {i} - Class: {class_name}\",\n                show_audio=True\n            )\n        \n        attempts += 1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test: Verifica Non-Overlap tra Node Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\nprint(\"TEST: Verifico non-overlap tra nodi con stessa classe\")\nprint(\"=\" * 80)\n\n# Test: Crea 2 dataset con stessa classe ma node_split_id diverso\ntest_class = 'dog'\n\nprint(f\"\\nCreating two datasets for class '{test_class}' with different node_split_id...\")\n\nsplit_0_dataset = VEGASDataset(\n    root_dir=str(VEGAS_ROOT),\n    selected_classes=[test_class],\n    node_split_id=0,  # Split 0\n    samples_per_node=20,  # RIDOTTO\n    train_ratio=1.0,\n    val_ratio=0.0,\n    test_ratio=0.0,\n    split='train',\n    enable_ast_cache=False,\n    load_audio=False,  # Disabilita audio per velocit√†\n    load_image=False,  # Disabilita immagine per velocit√†\n    load_video=False\n)\n\nsplit_1_dataset = VEGASDataset(\n    root_dir=str(VEGAS_ROOT),\n    selected_classes=[test_class],\n    node_split_id=1,  # Split 1 (diverso!)\n    samples_per_node=20,  # RIDOTTO\n    train_ratio=1.0,\n    val_ratio=0.0,\n    test_ratio=0.0,\n    split='train',\n    enable_ast_cache=False,\n    load_audio=False,\n    load_image=False,\n    load_video=False\n)\n\n# Raccogli sample IDs\nsplit_0_ids = set()\nfor idx in range(len(split_0_dataset)):\n    sample = split_0_dataset[idx]\n    split_0_ids.add(sample.get('sample_id', idx))\n\nsplit_1_ids = set()\nfor idx in range(len(split_1_dataset)):\n    sample = split_1_dataset[idx]\n    split_1_ids.add(sample.get('sample_id', idx))\n\n# Check overlap\noverlap = split_0_ids.intersection(split_1_ids)\n\nprint(f\"\\nClass: {test_class}\")\nprint(f\"Node Split 0 samples: {len(split_0_ids)}\")\nprint(f\"Node Split 1 samples: {len(split_1_ids)}\")\nprint(f\"Overlap: {len(overlap)} samples\")\n\nif len(overlap) == 0:\n    print(\"\\n‚úì SUCCESS: No overlap between node splits!\")\nelse:\n    print(f\"\\n‚ö†Ô∏è  WARNING: Found {len(overlap)} overlapping samples!\")\n    print(f\"Overlapping IDs: {list(overlap)[:10]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Statistiche Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def print_dataset_statistics(datasets_list, title=\"Dataset Statistics\"):\n    \"\"\"Stampa statistiche dettagliate per una lista di dataset\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(title)\n    print(\"=\" * 80)\n    \n    total_samples = 0\n    \n    for i, item in enumerate(datasets_list):\n        if isinstance(item, tuple):\n            label, dataset = item\n        else:\n            label, dataset = f\"Dataset {i}\", item\n            \n        num_samples = len(dataset)\n        \n        print(f\"\\n{label}:\")\n        print(f\"  Total samples: {num_samples:4d}\")\n        \n        total_samples += num_samples\n    \n    print(\"\\n\" + \"-\" * 80)\n    print(f\"Grand Total: {total_samples:5d} samples\")\n    print(\"=\" * 80)\n\n# Statistiche per single-class datasets\nprint_dataset_statistics(single_class_datasets, \"Single-Class Datasets Statistics\")\n\n# Statistiche per multi-class datasets\nprint_dataset_statistics(multi_class_datasets, \"Multi-Class Datasets Statistics\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizzazione Comparativa: Stessa Classe, Split Diversi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\nprint(\"COMPARATIVE VISUALIZATION: Same Class, Different Node Splits\")\nprint(\"=\" * 80)\n\n# Crea 2 dataset con stessa classe ma split diversi (RIDOTTO A 2 INVECE DI 3)\ntest_class = 'dog'\ncomparison_datasets = []\n\nprint(f\"\\nCreating 2 datasets for class '{test_class}' with different node_split_id...\")\n\nfor split_id in range(2):  # RIDOTTO A 2\n    dataset = VEGASDataset(\n        root_dir=str(VEGAS_ROOT),\n        selected_classes=[test_class],\n        node_split_id=split_id,\n        samples_per_node=10,  # RIDOTTO\n        train_ratio=1.0,\n        val_ratio=0.0,\n        test_ratio=0.0,\n        split='train',\n        enable_ast_cache=False,\n        load_audio=True,\n        load_image=True,\n        load_video=False\n    )\n    comparison_datasets.append(dataset)\n    print(f\"  Split {split_id}: {len(dataset)} samples\")\n\n# Visualizza 1 sample da ogni split\nprint(f\"\\nComparing samples from 2 different node splits:\\n\")\n\nfor split_id, dataset in enumerate(comparison_datasets):\n    if len(dataset) > 0:\n        sample = dataset[0]  # Primo sample\n        visualize_sample(\n            sample,\n            title=f\"Split {split_id} - Class: {test_class}\",\n            show_audio=True\n        )"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Bilanciamento Classi (Multi-Class Node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\nprint(\"TEST: Class Balance in Multi-Class Datasets\")\nprint(\"=\" * 80)\n\nfor i, (classes, dataset) in enumerate(multi_class_datasets):\n    print(f\"\\nMulti-Class Dataset {i}:\")\n    print(f\"Expected classes: {classes}\")\n    print(f\"Total samples: {len(dataset)}\")\n    \n    # Conta samples per classe\n    class_counts = {}\n    for idx in range(len(dataset)):\n        sample = dataset[idx]\n        class_name = sample.get('class_name', 'unknown')\n        class_counts[class_name] = class_counts.get(class_name, 0) + 1\n    \n    print(f\"\\nClass distribution:\")\n    for cls in classes:\n        count = class_counts.get(cls, 0)\n        percentage = (count / len(dataset)) * 100 if len(dataset) > 0 else 0\n        print(f\"  {cls:20s}: {count:3d} samples ({percentage:5.1f}%)\")\n    \n    print(\"-\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Sample per Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Salva alcuni samples per debugging\noutput_dir = Path(\"debug_samples\")\noutput_dir.mkdir(exist_ok=True)\n\nprint(f\"Exporting debug samples to: {output_dir}\\n\")\n\nfor class_name, dataset in single_class_datasets[:2]:  # Solo primi 2 dataset\n    if len(dataset) > 0:\n        sample = dataset[0]\n        \n        # Salva immagine\n        image = sample['image']\n        if isinstance(image, torch.Tensor):\n            # Move to CPU first\n            image = image.cpu().permute(1, 2, 0).numpy()\n        if image.min() < 0:\n            image = (image - image.min()) / (image.max() - image.min())\n        image = (image * 255).astype(np.uint8)\n        \n        img_pil = Image.fromarray(image)\n        img_path = output_dir / f\"{class_name}_image.png\"\n        img_pil.save(img_path)\n        print(f\"‚úì Saved: {img_path}\")\n        \n        # Salva audio\n        if 'audio' in sample:\n            audio = sample['audio']\n            if isinstance(audio, torch.Tensor):\n                # Move to CPU first\n                audio = audio.cpu().numpy()\n            \n            sample_rate = sample.get('sample_rate', 16000)\n            audio_path = output_dir / f\"{class_name}_audio.wav\"\n            \n            import scipy.io.wavfile as wavfile\n            wavfile.write(audio_path, sample_rate, audio)\n            print(f\"‚úì Saved: {audio_path}\")\n\nprint(f\"\\n‚úì Debug samples exported to {output_dir}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nQuesto notebook ha testato:\n\n‚úÖ **Single-class datasets**: Dataset con una classe per nodo  \n‚úÖ **Multi-class datasets**: Dataset con pi√π classi per nodo  \n‚úÖ **Visualizzazione**: Immagini + audio per ogni sample  \n‚úÖ **Non-overlap**: Verifica che split diversi non condividano samples  \n‚úÖ **Bilanciamento**: Distribuzione classi in dataset multi-classe  \n‚úÖ **Statistiche**: Numero samples per dataset  \n\n### Parametri Chiave VEGASDataset:\n\n- `selected_classes`: Lista classi da caricare\n- `node_split_id`: ID split (0, 1, 2...) per evitare overlap tra nodi\n- `samples_per_node`: Numero totale samples da caricare\n- `train_ratio`, `val_ratio`, `test_ratio`: Proporzioni split\n- `split`: 'train', 'val', 'test' - quale split caricare\n\n### Esempio Uso:\n\n```python\n# Dataset con singola classe\ndataset = VEGASDataset(\n    root_dir=str(VEGAS_ROOT),\n    selected_classes=['dog'],\n    node_split_id=0,\n    samples_per_node=200,\n    split='train',\n    enable_ast_cache=False\n)\n\n# Dataset con pi√π classi\ndataset = VEGASDataset(\n    root_dir=str(VEGAS_ROOT),\n    selected_classes=['dog', 'chainsaw', 'helicopter'],\n    node_split_id=0,\n    samples_per_node=300,\n    split='train',\n    enable_ast_cache=False\n)\n```"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}