{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creazione Embedding con FLUX CLIP Text Encoder\n",
    "\n",
    "Questo notebook crea embedding usando il text encoder di CLIP dal modello FLUX di Hugging Face con prompt vuoto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installazione delle dipendenze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch diffusers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Caricamento del modello CLIP Text Encoder da FLUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci il device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Carica il text encoder e tokenizer da FLUX\n",
    "model_id = \"black-forest-labs/FLUX.1-dev\"  # o \"black-forest-labs/FLUX.1-schnell\"\n",
    "\n",
    "print(\"Loading CLIP text encoder...\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\n",
    "    model_id,\n",
    "    subfolder=\"text_encoder\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ")\n",
    "text_encoder.to(device)\n",
    "text_encoder.eval()\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    subfolder=\"tokenizer\"\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creazione degli embedding con prompt vuoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt vuoto\n",
    "prompt = \"\"\n",
    "\n",
    "# Tokenizza il prompt\n",
    "text_inputs = tokenizer(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "text_input_ids = text_inputs.input_ids.to(device)\n",
    "\n",
    "# Genera gli embedding\n",
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(\n",
    "        text_input_ids,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    \n",
    "    # Ottieni gli embedding finali\n",
    "    prompt_embeds = text_embeddings.last_hidden_state\n",
    "    pooled_embeds = text_embeddings.pooler_output\n",
    "\n",
    "print(f\"Prompt embeddings shape: {prompt_embeds.shape}\")\n",
    "print(f\"Pooled embeddings shape: {pooled_embeds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizzazione delle informazioni sugli embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converti in numpy per analisi\n",
    "prompt_embeds_np = prompt_embeds.cpu().numpy()\n",
    "pooled_embeds_np = pooled_embeds.cpu().numpy()\n",
    "\n",
    "print(\"=== Informazioni sugli Embedding ===\")\n",
    "print(f\"\\nPrompt embeddings:\")\n",
    "print(f\"  Shape: {prompt_embeds_np.shape}\")\n",
    "print(f\"  Mean: {prompt_embeds_np.mean():.6f}\")\n",
    "print(f\"  Std: {prompt_embeds_np.std():.6f}\")\n",
    "print(f\"  Min: {prompt_embeds_np.min():.6f}\")\n",
    "print(f\"  Max: {prompt_embeds_np.max():.6f}\")\n",
    "\n",
    "print(f\"\\nPooled embeddings:\")\n",
    "print(f\"  Shape: {pooled_embeds_np.shape}\")\n",
    "print(f\"  Mean: {pooled_embeds_np.mean():.6f}\")\n",
    "print(f\"  Std: {pooled_embeds_np.std():.6f}\")\n",
    "print(f\"  Min: {pooled_embeds_np.min():.6f}\")\n",
    "print(f\"  Max: {pooled_embeds_np.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salvataggio degli embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva gli embedding in formato numpy\n",
    "np.save(\"flux_clip_empty_prompt_embeds.npy\", prompt_embeds_np)\n",
    "np.save(\"flux_clip_empty_pooled_embeds.npy\", pooled_embeds_np)\n",
    "\n",
    "# Salva anche in formato PyTorch\n",
    "torch.save({\n",
    "    'prompt_embeds': prompt_embeds,\n",
    "    'pooled_embeds': pooled_embeds\n",
    "}, \"flux_clip_empty_embeddings.pt\")\n",
    "\n",
    "print(\"Embedding salvati con successo!\")\n",
    "print(\"  - flux_clip_empty_prompt_embeds.npy\")\n",
    "print(\"  - flux_clip_empty_pooled_embeds.npy\")\n",
    "print(\"  - flux_clip_empty_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (Opzionale) Confronto con prompt non vuoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confronta con un prompt di esempio\n",
    "test_prompt = \"a beautiful landscape\"\n",
    "\n",
    "test_inputs = tokenizer(\n",
    "    test_prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ").input_ids.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_embeddings = text_encoder(test_inputs)\n",
    "    test_embeds = test_embeddings.last_hidden_state\n",
    "\n",
    "# Calcola la distanza tra empty prompt e test prompt\n",
    "distance = torch.norm(prompt_embeds - test_embeds).item()\n",
    "print(f\"Distanza L2 tra prompt vuoto e '{test_prompt}': {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. (Opzionale) Funzione riutilizzabile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_embeddings(prompt, text_encoder, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Genera embedding CLIP per un dato prompt.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Il prompt testuale\n",
    "        text_encoder: Il modello CLIP text encoder\n",
    "        tokenizer: Il tokenizer CLIP\n",
    "        device: Il device (cuda/cpu)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (prompt_embeds, pooled_embeds)\n",
    "    \"\"\"\n",
    "    text_inputs = tokenizer(\n",
    "        prompt,\n",
    "        padding=\"max_length\",\n",
    "        max_length=tokenizer.model_max_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    text_input_ids = text_inputs.input_ids.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        text_embeddings = text_encoder(\n",
    "            text_input_ids,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        prompt_embeds = text_embeddings.last_hidden_state\n",
    "        pooled_embeds = text_embeddings.pooler_output\n",
    "    \n",
    "    return prompt_embeds, pooled_embeds\n",
    "\n",
    "# Esempio di utilizzo\n",
    "empty_embeds, empty_pooled = get_clip_embeddings(\"\", text_encoder, tokenizer, device)\n",
    "print(f\"Embedding generati: {empty_embeds.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
