{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test VEGAS Dataset Embeddings Cache\n",
    "\n",
    "Questo notebook testa la creazione e il caricamento della cache degli embeddings per il dataset VEGAS.\n",
    "\n",
    "## Obiettivi:\n",
    "1. Caricare il dataset VEGAS\n",
    "2. Calcolare gli embeddings audio tramite AST model\n",
    "3. Salvare gli embeddings in una cache\n",
    "4. Testare il ricaricamento dalla cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/lpala/fedgfe\n"
     ]
    }
   ],
   "source": [
    "# Setup working directory\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set working directory to project root\n",
    "home_dir = os.path.expanduser('~')\n",
    "project_dir = os.path.join(home_dir, 'fedgfe')\n",
    "os.chdir(project_dir)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Add system directory to path\n",
    "sys.path.insert(0, os.path.join(project_dir, 'system'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Imports\nimport torch\nimport numpy as np\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport json\nimport pickle\nfrom datetime import datetime\n\n# Dataset imports\nfrom system.datautils.dataset_vegas import VEGASDataset\n\n# Model imports\nfrom transformers import ASTFeatureExtractor, ASTModel\n\nprint(\"Imports successful\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configurazione e parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Batch size: 8\n",
      "Cache directory: cache/embeddings/vegas\n",
      "Selected classes: ['chainsaw']\n"
     ]
    }
   ],
   "source": [
    "# Parametri\n",
    "DATASET_PATH = 'dataset/Audio/VEGAS'\n",
    "CACHE_DIR = 'cache/embeddings/vegas'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# AST Model\n",
    "AST_MODEL_NAME = 'MIT/ast-finetuned-audioset-10-10-0.4593'\n",
    "\n",
    "# Selected classes (tutte le 10 classi VEGAS)\n",
    "# SELECTED_CLASSES = [\n",
    "#     'baby_cry', 'chainsaw', 'dog', 'drum', 'fireworks',\n",
    "#     'helicopter', 'printer', 'rail_transport', 'snoring', 'water_flowing'\n",
    "# ]\n",
    "\n",
    "SELECTED_CLASSES = [\n",
    "    'chainsaw'\n",
    "]\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Cache directory: {CACHE_DIR}\")\n",
    "print(f\"Selected classes: {SELECTED_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Caricamento dataset VEGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VEGAS dataset...\n",
      "Dataset loaded: 100 samples\n",
      "Active classes: {'chainsaw': 1}\n",
      "\n",
      "Sample keys: dict_keys(['audio', 'text_emb', 'label', 'audio_filename', 'image_filename', 'video_filename', 'class_name', 'video_id', 'file_id', 'sample_idx', 'ytid', 'start_second', 'end_second', 'caption'])\n",
      "Audio shape: torch.Size([80000])\n",
      "Class name: chainsaw\n",
      "Sample ID: N/A\n"
     ]
    }
   ],
   "source": [
    "# Carica dataset VEGAS\n",
    "print(\"Loading VEGAS dataset...\")\n",
    "dataset = VEGASDataset(\n",
    "    root_dir=DATASET_PATH,\n",
    "    ast_cache_dir = CACHE_DIR,\n",
    "    samples_per_node=100,\n",
    "    node_split_id=0,\n",
    "    selected_classes=SELECTED_CLASSES,\n",
    "    enable_ast_cache = True,\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded: {len(dataset)} samples\")\n",
    "print(f\"Active classes: {dataset.active_classes}\")\n",
    "\n",
    "# Mostra un sample di esempio\n",
    "sample = dataset[0]\n",
    "print(f\"\\nSample keys: {sample.keys()}\")\n",
    "print(f\"Audio shape: {sample['audio'].shape}\")\n",
    "print(f\"Class name: {sample['class_name']}\")\n",
    "print(f\"Sample ID: {sample.get('sample_id', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inizializzazione AST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AST model: MIT/ast-finetuned-audioset-10-10-0.4593\n",
      "AST model loaded on cuda\n",
      "Model parameters: 86.19M\n"
     ]
    }
   ],
   "source": [
    "# Carica AST model e feature extractor\n",
    "print(f\"Loading AST model: {AST_MODEL_NAME}\")\n",
    "ast_feature_extractor = ASTFeatureExtractor.from_pretrained(AST_MODEL_NAME)\n",
    "ast_model = ASTModel.from_pretrained(AST_MODEL_NAME)\n",
    "ast_model = ast_model.to(DEVICE)\n",
    "ast_model.eval()\n",
    "\n",
    "print(f\"AST model loaded on {DEVICE}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in ast_model.parameters()) / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Funzioni per calcolare e salvare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def build_index_map(dataset):\n    \"\"\"\n    Costruisce mappa cache_key → dataset_index per accesso O(1).\n    \n    Args:\n        dataset: VEGASDataset instance\n    \n    Returns:\n        dict: {cache_key: dataset_index}\n    \"\"\"\n    index_map = {}\n    for idx in range(len(dataset)):\n        sample = dataset.samples[idx]\n        cache_key = f\"{sample['class_name']}:{sample['file_id']}\"\n        index_map[cache_key] = idx\n    return index_map\n\n\ndef compute_audio_embeddings(dataset, ast_model, ast_feature_extractor, device, batch_size=8):\n    \"\"\"\n    Calcola gli audio embeddings per tutti i campioni del dataset.\n    \n    Uses cache_key = \"{class_name}:{file_id}\" (e.g., \"dog:video_00001\")\n    \n    Returns:\n        tuple: (embeddings_array, cache_keys, index_map)\n            embeddings_array: numpy array (n_samples, seq_len, hidden_dim)\n            cache_keys: list of cache keys in order\n            index_map: {cache_key: array_index}\n    \"\"\"\n    all_embeddings = []\n    cache_keys = []\n    index_map = {}\n    \n    print(f\"\\nComputing embeddings for {len(dataset)} samples...\")\n    \n    # Process in batches\n    for i in tqdm(range(0, len(dataset), batch_size), desc=\"Processing batches\"):\n        batch_end = min(i + batch_size, len(dataset))\n        batch_indices = list(range(i, batch_end))\n        batch_samples = [dataset[j] for j in batch_indices]\n        \n        # Extract audio and metadata\n        batch_audio = []\n        batch_cache_keys = []\n        \n        for idx, sample in zip(batch_indices, batch_samples):\n            audio = sample['audio']\n            if isinstance(audio, torch.Tensor):\n                audio = audio.cpu().numpy()\n            batch_audio.append(audio)\n            \n            # Create cache key: {class_name}:{file_id}\n            cache_key = f\"{sample['class_name']}:{sample['file_id']}\"\n            batch_cache_keys.append(cache_key)\n        \n        # Process audio through AST\n        with torch.no_grad():\n            # Feature extraction\n            audio_inputs = ast_feature_extractor(\n                batch_audio,\n                sampling_rate=16000,\n                return_tensors=\"pt\",\n                padding=True\n            ).input_values.to(device)\n            \n            # Get embeddings\n            ast_output = ast_model(audio_inputs).last_hidden_state  # (batch, seq_len, hidden_dim)\n            \n            # Convert to numpy and store\n            ast_output_np = ast_output.cpu().numpy()\n            \n            for emb, cache_key in zip(ast_output_np, batch_cache_keys):\n                all_embeddings.append(emb)\n                cache_keys.append(cache_key)\n                index_map[cache_key] = len(cache_keys) - 1\n        \n        # Cleanup\n        del audio_inputs, ast_output, ast_output_np\n        if device == 'cuda':\n            torch.cuda.empty_cache()\n    \n    # Stack all embeddings into single array\n    embeddings_array = np.stack(all_embeddings, axis=0)\n    \n    print(f\"\\nComputed embeddings for {len(embeddings_array)} samples\")\n    print(f\"Embeddings array shape: {embeddings_array.shape}\")\n    print(f\"Created index map with {len(index_map)} entries\")\n    \n    return embeddings_array, cache_keys, index_map\n\n\ndef save_embeddings_cache_mmap(embeddings_array, cache_keys, index_map, cache_dir, metadata=None):\n    \"\"\"\n    Salva gli embeddings usando numpy memmap per accesso efficiente.\n    \n    Args:\n        embeddings_array: numpy array (n_samples, seq_len, hidden_dim)\n        cache_keys: list of cache keys\n        index_map: Dictionary cache_key → array_index\n        cache_dir: Directory dove salvare la cache\n        metadata: Optional metadata dict\n    \"\"\"\n    cache_path = Path(cache_dir)\n    cache_path.mkdir(parents=True, exist_ok=True)\n    \n    # Salva embeddings come numpy array (per mmap)\n    embeddings_file = cache_path / 'audio_embeddings.npy'\n    np.save(embeddings_file, embeddings_array)\n    print(f\"\\nEmbeddings array saved to: {embeddings_file}\")\n    print(f\"File size: {embeddings_file.stat().st_size / (1024**2):.2f} MB\")\n    print(f\"Shape: {embeddings_array.shape}, dtype: {embeddings_array.dtype}\")\n    \n    # Salva cache_keys come lista (per ricostruire cache_key da index)\n    cache_keys_file = cache_path / 'cache_keys.pkl'\n    with open(cache_keys_file, 'wb') as f:\n        pickle.dump(cache_keys, f)\n    print(f\"Cache keys saved to: {cache_keys_file}\")\n    \n    # Salva index map\n    index_map_file = cache_path / 'index_map.pkl'\n    with open(index_map_file, 'wb') as f:\n        pickle.dump(index_map, f)\n    print(f\"Index map saved to: {index_map_file}\")\n    print(f\"File size: {index_map_file.stat().st_size / 1024:.2f} KB\")\n    \n    # Salva metadata\n    metadata_dict = metadata or {}\n    metadata_dict.update({\n        'num_samples': len(embeddings_array),\n        'embedding_shape': list(embeddings_array.shape),\n        'embedding_dtype': str(embeddings_array.dtype),\n        'timestamp': datetime.now().isoformat(),\n        'cache_version': '3.0',  # Version 3.0 with mmap support\n        'cache_key_format': '{class_name}:{file_id}',\n        'mmap_enabled': True\n    })\n    \n    metadata_file = cache_path / 'metadata.json'\n    with open(metadata_file, 'w') as f:\n        json.dump(metadata_dict, f, indent=2)\n    print(f\"Metadata saved to: {metadata_file}\")\n    \n    return embeddings_file\n\n\ndef load_embeddings_cache_mmap(cache_dir, mmap_mode='r'):\n    \"\"\"\n    Carica gli embeddings usando numpy memmap (lazy loading).\n    \n    Args:\n        cache_dir: Directory cache\n        mmap_mode: Modalità mmap ('r' = read-only, 'r+' = read-write, 'c' = copy-on-write)\n    \n    Returns:\n        tuple: (embeddings_mmap, index_map, cache_keys, metadata_dict)\n            embeddings_mmap: numpy memmap array (accesso lazy)\n            index_map: {cache_key: array_index}\n            cache_keys: list of cache keys\n            metadata_dict: metadata\n    \"\"\"\n    cache_path = Path(cache_dir)\n    \n    # Load metadata first\n    metadata_file = cache_path / 'metadata.json'\n    metadata_dict = {}\n    if metadata_file.exists():\n        with open(metadata_file, 'r') as f:\n            metadata_dict = json.load(f)\n        print(f\"Metadata: {metadata_dict}\")\n    \n    # Load embeddings as memmap (NO CARICAMENTO IN RAM!)\n    embeddings_file = cache_path / 'audio_embeddings.npy'\n    if not embeddings_file.exists():\n        raise FileNotFoundError(f\"Cache file not found: {embeddings_file}\")\n    \n    print(f\"\\nLoading embeddings with mmap from: {embeddings_file}\")\n    embeddings_mmap = np.load(embeddings_file, mmap_mode=mmap_mode)\n    print(f\"Embeddings mmap loaded: shape={embeddings_mmap.shape}, dtype={embeddings_mmap.dtype}\")\n    print(f\"Memory mapped (not loaded in RAM)\")\n    \n    # Load cache_keys\n    cache_keys_file = cache_path / 'cache_keys.pkl'\n    with open(cache_keys_file, 'rb') as f:\n        cache_keys = pickle.load(f)\n    print(f\"Loaded {len(cache_keys)} cache keys\")\n    \n    # Load index map\n    index_map_file = cache_path / 'index_map.pkl'\n    with open(index_map_file, 'rb') as f:\n        index_map = pickle.load(f)\n    print(f\"Loaded index map with {len(index_map)} entries\")\n    \n    return embeddings_mmap, index_map, cache_keys, metadata_dict\n\n\ndef get_embedding_from_cache(cache_key, embeddings_mmap, index_map):\n    \"\"\"\n    Recupera un embedding dalla cache usando mmap (accesso lazy).\n    \n    Args:\n        cache_key: Cache key (format: \"{class_name}:{file_id}\")\n        embeddings_mmap: numpy memmap array\n        index_map: Index map dictionary\n    \n    Returns:\n        numpy array: embedding (seq_len, hidden_dim)\n    \"\"\"\n    idx = index_map.get(cache_key)\n    if idx is None:\n        raise KeyError(f\"Cache key '{cache_key}' not found in index_map\")\n    \n    # L'accesso all'array mmap carica SOLO questo elemento in RAM\n    return embeddings_mmap[idx]\n\n\ndef get_sample_from_cache_key(dataset, cache_key, index_map):\n    \"\"\"\n    Recupera un sample dal dataset usando il cache_key.\n    \n    Args:\n        dataset: VEGASDataset instance\n        cache_key: Cache key (format: \"{class_name}:{file_id}\")\n        index_map: Index map dictionary (dataset index map, not cache index map)\n    \n    Returns:\n        Sample dictionary or None if not found\n    \"\"\"\n    # Parse cache_key\n    class_name, file_id = cache_key.split(':')\n    \n    # Linear search in dataset.samples\n    for idx in range(len(dataset)):\n        sample = dataset.samples[idx]\n        if sample['file_id'] == file_id and sample['class_name'] == class_name:\n            return dataset[idx]\n    \n    return None\n\n\nprint(\"Functions defined (Solution 2: with mmap support)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calcolo e salvataggio embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compute embeddings\nembeddings_array, cache_keys, index_map = compute_audio_embeddings(\n    dataset=dataset,\n    ast_model=ast_model,\n    ast_feature_extractor=ast_feature_extractor,\n    device=DEVICE,\n    batch_size=BATCH_SIZE\n)\n\n# Mostra statistiche\nprint(\"\\n=== Embeddings Statistics ===\")\nprint(f\"Embeddings array shape: {embeddings_array.shape}\")\nprint(f\"Embeddings array dtype: {embeddings_array.dtype}\")\nprint(f\"Total samples: {len(embeddings_array)}\")\nprint(f\"Memory size: {embeddings_array.nbytes / (1024**2):.2f} MB\")\n\n# Count per class\nclass_counts = {}\nfor cache_key in cache_keys:\n    class_name = cache_key.split(':')[0]\n    class_counts[class_name] = class_counts.get(class_name, 0) + 1\n\nprint(\"\\nSamples per class:\")\nfor class_name, count in sorted(class_counts.items()):\n    print(f\"  {class_name}: {count}\")\n\n# Show some example cache keys\nprint(\"\\nExample cache keys:\")\nfor i, cache_key in enumerate(cache_keys[:5]):\n    print(f\"  {cache_key}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Salva embeddings in cache con mmap support\nmetadata = {\n    'dataset': 'VEGAS',\n    'ast_model': AST_MODEL_NAME,\n    'selected_classes': SELECTED_CLASSES,\n    'samples_per_class': class_counts\n}\n\ncache_file = save_embeddings_cache_mmap(\n    embeddings_array=embeddings_array,\n    cache_keys=cache_keys,\n    index_map=index_map,\n    cache_dir=CACHE_DIR,\n    metadata=metadata\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test caricamento dalla cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading from cache\n",
    "print(\"\\n=== Testing cache loading ===\")\n",
    "loaded_embeddings, loaded_index_map, loaded_metadata = load_embeddings_cache(CACHE_DIR)\n",
    "\n",
    "print(f\"\\nLoaded {len(loaded_embeddings)} embeddings\")\n",
    "print(f\"Loaded {len(loaded_index_map)} index map entries\")\n",
    "print(f\"Metadata: {loaded_metadata}\")\n",
    "\n",
    "# Verify data integrity\n",
    "cache_key = list(loaded_embeddings.keys())[0]\n",
    "sample_data = loaded_embeddings[cache_key]\n",
    "print(f\"\\nExample cache key: {cache_key}\")\n",
    "print(f\"Sample data keys: {sample_data.keys()}\")\n",
    "print(f\"Embedding shape: {sample_data['embedding'].shape}\")\n",
    "print(f\"Class name: {sample_data['class_name']}\")\n",
    "print(f\"File ID: {sample_data['file_id']}\")\n",
    "print(f\"Dataset index: {loaded_index_map[cache_key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test accesso con cache_key e index_map (Soluzione 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Prendi un cache_key casuale\n",
    "test_cache_key = random.choice(list(loaded_embeddings.keys()))\n",
    "print(f\"Testing cache key: {test_cache_key}\")\n",
    "\n",
    "# Metodo 1: Accesso diretto usando index_map (O(1))\n",
    "dataset_idx = loaded_index_map[test_cache_key]\n",
    "print(f\"Dataset index from index_map: {dataset_idx}\")\n",
    "sample = dataset[dataset_idx]\n",
    "\n",
    "# Metodo 2: Usando la funzione helper\n",
    "sample_alt = get_sample_from_cache_key(dataset, test_cache_key, loaded_index_map)\n",
    "\n",
    "print(f\"\\nSample class: {sample['class_name']}\")\n",
    "print(f\"Sample file_id: {sample['file_id']}\")\n",
    "\n",
    "# Compute fresh embedding\n",
    "audio = sample['audio']\n",
    "if isinstance(audio, torch.Tensor):\n",
    "    audio = audio.cpu().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    audio_inputs = ast_feature_extractor(\n",
    "        audio,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    ).input_values.to(DEVICE)\n",
    "    \n",
    "    fresh_embedding = ast_model(audio_inputs).last_hidden_state.cpu()\n",
    "\n",
    "# Get from cache\n",
    "cached_embedding = loaded_embeddings[test_cache_key]['embedding']\n",
    "\n",
    "# Compare\n",
    "print(f\"\\nFresh embedding shape: {fresh_embedding.shape}\")\n",
    "print(f\"Cached embedding shape: {cached_embedding.shape}\")\n",
    "\n",
    "# Calculate difference\n",
    "diff = torch.abs(fresh_embedding - cached_embedding).mean()\n",
    "print(f\"\\nMean absolute difference: {diff.item():.8f}\")\n",
    "\n",
    "if diff < 1e-5:\n",
    "    print(\"✓ Embeddings match! Cache is working correctly.\")\n",
    "else:\n",
    "    print(\"⚠ Warning: Embeddings don't match perfectly (might be due to padding/batching)\")\n",
    "\n",
    "# Verify both methods return same sample\n",
    "print(f\"\\n✓ Both access methods return same sample: {sample['file_id'] == sample_alt['file_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Benchmark: tempo di caricamento e accesso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"=== Benchmark 1: Cache Loading Speed ===\")\n",
    "\n",
    "# Time cache loading\n",
    "start = time.time()\n",
    "cached_embs, cached_index_map, _ = load_embeddings_cache(CACHE_DIR)\n",
    "cache_time = time.time() - start\n",
    "print(f\"Cache loading time: {cache_time:.3f}s\")\n",
    "\n",
    "# Time computing a few samples\n",
    "num_test_samples = min(50, len(dataset))\n",
    "print(f\"\\n=== Benchmark 2: On-the-fly vs Cache ({num_test_samples} samples) ===\")\n",
    "start = time.time()\n",
    "for i in range(num_test_samples):\n",
    "    sample = dataset[i]\n",
    "    audio = sample['audio']\n",
    "    if isinstance(audio, torch.Tensor):\n",
    "        audio = audio.cpu().numpy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        audio_inputs = ast_feature_extractor(\n",
    "            audio,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        ).input_values.to(DEVICE)\n",
    "        _ = ast_model(audio_inputs).last_hidden_state.cpu()\n",
    "\n",
    "compute_time = time.time() - start\n",
    "print(f\"On-the-fly computation time: {compute_time:.3f}s\")\n",
    "print(f\"Average time per sample: {compute_time/num_test_samples:.4f}s\")\n",
    "\n",
    "# Extrapolate to full dataset\n",
    "estimated_full_time = (compute_time / num_test_samples) * len(dataset)\n",
    "print(f\"\\nEstimated time for full dataset ({len(dataset)} samples): {estimated_full_time:.2f}s\")\n",
    "print(f\"Speedup with cache: {estimated_full_time/cache_time:.1f}x\")\n",
    "\n",
    "print(f\"\\n=== Benchmark 3: Sample Access Speed ===\")\n",
    "\n",
    "# Test index_map lookup speed\n",
    "num_lookups = 1000\n",
    "test_cache_keys = list(cached_index_map.keys())[:min(num_lookups, len(cached_index_map))]\n",
    "\n",
    "# Method 1: With index_map (O(1))\n",
    "start = time.time()\n",
    "for cache_key in test_cache_keys:\n",
    "    idx = cached_index_map[cache_key]\n",
    "    _ = dataset[idx]\n",
    "fast_time = time.time() - start\n",
    "\n",
    "print(f\"With index_map ({len(test_cache_keys)} lookups): {fast_time:.4f}s\")\n",
    "print(f\"Average per lookup: {fast_time/len(test_cache_keys)*1000:.4f}ms\")\n",
    "\n",
    "# Method 2: Linear search (O(n)) - just for comparison on a few samples\n",
    "num_slow_tests = min(10, len(test_cache_keys))\n",
    "start = time.time()\n",
    "for cache_key in test_cache_keys[:num_slow_tests]:\n",
    "    class_name, file_id = cache_key.split(':')\n",
    "    for idx in range(len(dataset)):\n",
    "        sample = dataset.samples[idx]\n",
    "        if sample['file_id'] == file_id and sample['class_name'] == class_name:\n",
    "            _ = dataset[idx]\n",
    "            break\n",
    "slow_time = time.time() - start\n",
    "\n",
    "print(f\"\\nLinear search ({num_slow_tests} lookups): {slow_time:.4f}s\")\n",
    "print(f\"Average per lookup: {slow_time/num_slow_tests*1000:.4f}ms\")\n",
    "print(f\"Speedup with index_map: {(slow_time/num_slow_tests)/(fast_time/len(test_cache_keys)):.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Test integrazione con VEGASDataset\n\nTestiamo i metodi appena implementati in VEGASDataset:\n- `save_ast_embeddings_to_cache()` - salva embeddings organizzati per classe\n- `load_ast_embeddings_from_cache()` - carica con mmap\n- `get_cached_ast_embedding()` - accesso O(1)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}