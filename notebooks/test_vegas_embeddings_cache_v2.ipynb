{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test VEGAS Dataset Embeddings Cache (v2 - Integrato)\n",
    "\n",
    "Test del sistema di caching integrato in VEGASDataset.\n",
    "\n",
    "## Features:\n",
    "1. Salvataggio incrementale (append) per classe\n",
    "2. Memory mapping (lazy loading)\n",
    "3. Cache key: `{class_name}:{file_id}`\n",
    "4. Accesso O(1) agli embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "home_dir = os.path.expanduser('~')\n",
    "project_dir = os.path.join(home_dir, 'fedgfe')\n",
    "os.chdir(project_dir)\n",
    "sys.path.insert(0, os.path.join(project_dir, 'system'))\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from system.datautils.dataset_vegas import VEGASDataset\n",
    "from transformers import ASTFeatureExtractor, ASTModel\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "DATASET_PATH = 'dataset/Audio/VEGAS'\n",
    "CACHE_DIR = 'cache/ast/vegas'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 8\n",
    "AST_MODEL_NAME = 'MIT/ast-finetuned-audioset-10-10-0.4593'\n",
    "\n",
    "# Test con 2 classi\n",
    "SELECTED_CLASSES = ['chainsaw', 'dog']\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Cache dir: {CACHE_DIR}\")\n",
    "print(f\"Classes: {SELECTED_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carica Dataset e AST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica dataset\n",
    "dataset = VEGASDataset(\n",
    "    root_dir=DATASET_PATH,\n",
    "    selected_classes=SELECTED_CLASSES,\n",
    "    samples_per_node=50,  # Limitiamo per test rapido\n",
    "    node_split_id=0,\n",
    "    ast_cache_dir=CACHE_DIR,\n",
    "    enable_ast_cache=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {len(dataset)} samples\")\n",
    "print(f\"Classes: {dataset.active_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica AST model\n",
    "ast_feature_extractor = ASTFeatureExtractor.from_pretrained(AST_MODEL_NAME)\n",
    "ast_model = ASTModel.from_pretrained(AST_MODEL_NAME)\n",
    "ast_model = ast_model.to(DEVICE)\n",
    "ast_model.eval()\n",
    "\n",
    "print(f\"AST model loaded on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simula workflow: Calcola embeddings AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simula il calcolo degli embeddings durante training\n",
    "# (come farebbe clientA2V)\n",
    "\n",
    "ast_outputs_by_class = {}\n",
    "\n",
    "print(f\"Calculating AST embeddings...\")\n",
    "for idx in tqdm(range(len(dataset))):\n",
    "    sample = dataset[idx]\n",
    "    \n",
    "    # Get audio\n",
    "    audio = sample['audio']\n",
    "    if isinstance(audio, torch.Tensor):\n",
    "        audio = audio.cpu().numpy()\n",
    "    \n",
    "    # Compute AST embedding\n",
    "    with torch.no_grad():\n",
    "        audio_inputs = ast_feature_extractor(\n",
    "            audio,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        ).input_values.to(DEVICE)\n",
    "        \n",
    "        ast_output = ast_model(audio_inputs).last_hidden_state\n",
    "    \n",
    "    # Organize by class\n",
    "    class_name = sample['class_name']\n",
    "    file_id = sample['file_id']\n",
    "    \n",
    "    if class_name not in ast_outputs_by_class:\n",
    "        ast_outputs_by_class[class_name] = {}\n",
    "    \n",
    "    ast_outputs_by_class[class_name][file_id] = ast_output.squeeze(0).cpu()\n",
    "\n",
    "print(f\"\\nCalculated embeddings:\")\n",
    "for class_name, embs in ast_outputs_by_class.items():\n",
    "    print(f\"  {class_name}: {len(embs)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test: Salva in cache (primo salvataggio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva usando il metodo di VEGASDataset\n",
    "saved_counts = dataset.save_ast_embeddings_to_cache(\n",
    "    ast_outputs_dict=ast_outputs_by_class,\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n",
    "\n",
    "print(f\"\\nSaved embeddings: {saved_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica struttura file\n",
    "import os\n",
    "\n",
    "print(f\"\\nCache structure:\")\n",
    "for root, dirs, files in os.walk(CACHE_DIR):\n",
    "    level = root.replace(CACHE_DIR, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        size = os.path.getsize(file_path) / 1024  # KB\n",
    "        print(f\"{subindent}{file} ({size:.2f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test: Append incrementale (simula secondo batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simula salvataggio di nuovi embeddings (es. secondo nodo o round successivo)\n",
    "# Creiamo alcuni fake embeddings per testare l'append\n",
    "\n",
    "print(\"Simulating append of new embeddings...\")\n",
    "\n",
    "new_embeddings = {}\n",
    "for class_name in SELECTED_CLASSES:\n",
    "    new_embeddings[class_name] = {\n",
    "        f'video_99{i:03d}': torch.randn(1214, 768)  # Fake embeddings\n",
    "        for i in range(5)  # 5 nuovi samples per classe\n",
    "    }\n",
    "\n",
    "saved_counts = dataset.save_ast_embeddings_to_cache(\n",
    "    ast_outputs_dict=new_embeddings,\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n",
    "\n",
    "print(f\"\\nAppended embeddings: {saved_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica che siano stati creati nuovi chunks\n",
    "for class_name in SELECTED_CLASSES:\n",
    "    manifest_file = os.path.join(CACHE_DIR, class_name, 'manifest.json')\n",
    "    with open(manifest_file, 'r') as f:\n",
    "        manifest = json.load(f)\n",
    "    \n",
    "    print(f\"\\nClass '{class_name}':\")\n",
    "    print(f\"  Total samples: {manifest['total_samples']}\")\n",
    "    print(f\"  Num chunks: {len(manifest['chunks'])}\")\n",
    "    for i, chunk in enumerate(manifest['chunks']):\n",
    "        print(f\"  Chunk {i}: {chunk['num_samples']} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test: Carica da cache con mmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica cache\n",
    "loaded_cache = dataset.load_ast_embeddings_from_cache(\n",
    "    cache_dir=CACHE_DIR,\n",
    "    classes=SELECTED_CLASSES\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded cache for {len(loaded_cache)} classes:\")\n",
    "for class_name, cache_info in loaded_cache.items():\n",
    "    print(f\"  {class_name}: {cache_info['manifest']['total_samples']} samples, \"\n",
    "          f\"{len(cache_info['chunks'])} chunks (mmap)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test: Accesso O(1) agli embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accesso con get_cached_ast_embedding()\n",
    "import random\n",
    "\n",
    "# Prendi un sample casuale\n",
    "test_idx = random.randint(0, len(dataset) - 1)\n",
    "sample = dataset.samples[test_idx]\n",
    "\n",
    "class_name = sample['class_name']\n",
    "file_id = sample['file_id']\n",
    "\n",
    "print(f\"Testing sample: class={class_name}, file_id={file_id}\")\n",
    "\n",
    "# Recupera da cache\n",
    "cached_emb = dataset.get_cached_ast_embedding(class_name, file_id)\n",
    "\n",
    "if cached_emb is not None:\n",
    "    print(f\"✓ Retrieved from cache: shape={cached_emb.shape}\")\n",
    "    \n",
    "    # Confronta con l'originale (se disponibile)\n",
    "    if class_name in ast_outputs_by_class and file_id in ast_outputs_by_class[class_name]:\n",
    "        original_emb = ast_outputs_by_class[class_name][file_id].numpy()\n",
    "        diff = np.abs(cached_emb - original_emb).mean()\n",
    "        print(f\"  Mean diff from original: {diff:.8f}\")\n",
    "        \n",
    "        if diff < 1e-6:\n",
    "            print(\"  ✓ Perfect match!\")\n",
    "else:\n",
    "    print(\"✗ Not found in cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test: Append duplicati (deve skippare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prova a salvare gli stessi embeddings (devono essere skippati)\n",
    "print(\"Testing duplicate detection...\")\n",
    "\n",
    "saved_counts = dataset.save_ast_embeddings_to_cache(\n",
    "    ast_outputs_dict=ast_outputs_by_class,  # Stessi di prima\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n",
    "\n",
    "print(f\"\\nDuplicate test result: {saved_counts}\")\n",
    "print(\"✓ All should be 0 (already cached)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Benchmark: Accesso mmap vs calcolo fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "num_tests = 20\n",
    "test_indices = random.sample(range(len(dataset)), min(num_tests, len(dataset)))\n",
    "\n",
    "# Test 1: Accesso da cache\n",
    "print(f\"Testing {num_tests} random samples...\")\n",
    "\n",
    "start = time.time()\n",
    "for idx in test_indices:\n",
    "    sample = dataset.samples[idx]\n",
    "    _ = dataset.get_cached_ast_embedding(sample['class_name'], sample['file_id'])\n",
    "cache_time = time.time() - start\n",
    "\n",
    "print(f\"Cache access time: {cache_time:.4f}s ({cache_time/num_tests*1000:.2f}ms per sample)\")\n",
    "\n",
    "# Test 2: Calcolo fresh\n",
    "start = time.time()\n",
    "for idx in test_indices:\n",
    "    sample = dataset[idx]\n",
    "    audio = sample['audio'].cpu().numpy() if isinstance(sample['audio'], torch.Tensor) else sample['audio']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        audio_inputs = ast_feature_extractor(\n",
    "            audio,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        ).input_values.to(DEVICE)\n",
    "        _ = ast_model(audio_inputs).last_hidden_state.cpu()\n",
    "\n",
    "fresh_time = time.time() - start\n",
    "\n",
    "print(f\"Fresh computation time: {fresh_time:.4f}s ({fresh_time/num_tests*1000:.2f}ms per sample)\")\n",
    "print(f\"\\nSpeedup: {fresh_time/cache_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusioni\n",
    "\n",
    "Sistema di caching integrato in VEGASDataset:\n",
    "\n",
    "### ✓ Features implementate:\n",
    "- Salvataggio per classe (file separati)\n",
    "- Append incrementale (nuovi chunks)\n",
    "- Rilevamento duplicati automatico\n",
    "- Memory mapping (lazy loading)\n",
    "- Accesso O(1) agli embeddings\n",
    "- Metadata integrati nel manifest\n",
    "- Thread-safe writes (atomic rename)\n",
    "\n",
    "### Struttura cache:\n",
    "```\n",
    "cache_dir/\n",
    "├── class_name/\n",
    "│   ├── embeddings_000.npy\n",
    "│   ├── embeddings_001.npy\n",
    "│   └── manifest.json\n",
    "└── ...\n",
    "```\n",
    "\n",
    "### API:\n",
    "```python\n",
    "# Salva (da clientA2V o server)\n",
    "dataset.save_ast_embeddings_to_cache(ast_outputs_by_class, cache_dir)\n",
    "\n",
    "# Carica (all'inizio training)\n",
    "dataset.load_ast_embeddings_from_cache(cache_dir)\n",
    "\n",
    "# Accedi (in __getitem__)\n",
    "emb = dataset.get_cached_ast_embedding(class_name, file_id)\n",
    "```\n",
    "\n",
    "### Prossimi passi:\n",
    "1. Integrare in clientA2V per salvare durante training\n",
    "2. Script standalone per pre-generare cache\n",
    "3. Modificare __getitem__ per usare cache quando disponibile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
