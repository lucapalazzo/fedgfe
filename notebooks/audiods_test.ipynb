{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Dataset Explorer\n",
    "## Interactive notebook per esplorare ESC-50 e VEGAS datasets\n",
    "\n",
    "Questo notebook permette di:\n",
    "- üéµ Ascoltare campioni audio\n",
    "- üñºÔ∏è Visualizzare immagini associate\n",
    "- üìä Vedere statistiche dei dataset\n",
    "- üîç Esplorare classi e samples in modo interattivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup e Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: detected 384 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "INFO:numexpr.utils:Note: NumExpr detected 384 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/lpala/fedgfe/system')\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display, HTML\n",
    "from PIL import Image\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import datasets\n",
    "from datautils.dataset_esc50 import ESC50Dataset\n",
    "from datautils.dataset_vegas import VEGASDataset\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions loaded!\n"
     ]
    }
   ],
   "source": [
    "def plot_waveform(waveform, sample_rate, title=\"Waveform\"):\n",
    "    \"\"\"Plot audio waveform\"\"\"\n",
    "    waveform = waveform.numpy()\n",
    "    num_frames = waveform.shape[-1]\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "    \n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(time_axis, waveform)\n",
    "    plt.grid(True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_spectrogram(waveform, sample_rate, title=\"Spectrogram\"):\n",
    "    \"\"\"Plot audio spectrogram\"\"\"\n",
    "    waveform = waveform.numpy()\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.specgram(waveform, Fs=sample_rate, cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.colorbar(label='Intensity (dB)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_image(image_tensor, title=\"Image\"):\n",
    "    \"\"\"Display image from tensor\"\"\"\n",
    "    # Denormalize if normalized\n",
    "    if image_tensor.min() < 0:\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        image_tensor = image_tensor * std + mean\n",
    "    \n",
    "    image_tensor = torch.clamp(image_tensor, 0, 1)\n",
    "    image = image_tensor.permute(1, 2, 0).numpy()\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_sample_info(sample):\n",
    "    \"\"\"Display sample metadata\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìã SAMPLE INFORMATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üè∑Ô∏è  Class: {sample['class_name']}\")\n",
    "    print(f\"üî¢ Label: {sample['label'].item()}\")\n",
    "    print(f\"üìù Audio file: {sample['audio_filename']}\")\n",
    "    print(f\"üñºÔ∏è  Image file: {sample['image_filename']}\")\n",
    "    print(f\"üìä Audio shape: {sample['audio'].shape}\")\n",
    "    if 'image' in sample:\n",
    "        print(f\"üé® Image shape: {sample['image'].shape}\")\n",
    "    if 'video' in sample:\n",
    "        print(f\"üé• Video shape: {sample['video'].shape}\")\n",
    "    \n",
    "    if 'fold' in sample:\n",
    "        print(f\"üìÅ Fold: {sample['fold']}\")\n",
    "    if 'caption' in sample and sample['caption']:\n",
    "        print(f\"üí¨ Caption: {sample['caption']}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "def play_audio(waveform, sample_rate):\n",
    "    \"\"\"Play audio in notebook\"\"\"\n",
    "    return Audio(waveform.numpy(), rate=sample_rate)\n",
    "\n",
    "print(\"‚úÖ Helper functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ESC-50 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ESC-50 dataset with classes: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datautils.dataset_esc50:ESC-50 Dataset initialized: 2000 samples, classes: 50, split: all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ ESC-50 Dataset loaded!\n",
      "   Total samples: 2000\n",
      "   Classes: ['airplane', 'breathing', 'brushing_teeth', 'can_opening', 'car_horn', 'cat', 'chainsaw', 'chirping_birds', 'church_bells', 'clapping', 'clock_alarm', 'clock_tick', 'coughing', 'cow', 'crackling_fire', 'crickets', 'crow', 'crying_baby', 'dog', 'door_wood_creaks', 'door_wood_knock', 'drinking_sipping', 'engine', 'fireworks', 'footsteps', 'frog', 'glass_breaking', 'hand_saw', 'helicopter', 'hen', 'insects', 'keyboard_typing', 'laughing', 'mouse_click', 'pig', 'pouring_water', 'rain', 'rooster', 'sea_waves', 'sheep', 'siren', 'sneezing', 'snoring', 'thunderstorm', 'toilet_flush', 'train', 'vacuum_cleaner', 'washing_machine', 'water_drops', 'wind']\n",
      "   Samples per class: {'dog': 40, 'chirping_birds': 40, 'vacuum_cleaner': 40, 'thunderstorm': 40, 'door_wood_knock': 40, 'can_opening': 40, 'crow': 40, 'clapping': 40, 'fireworks': 40, 'chainsaw': 40, 'airplane': 40, 'mouse_click': 40, 'pouring_water': 40, 'train': 40, 'sheep': 40, 'water_drops': 40, 'church_bells': 40, 'clock_alarm': 40, 'keyboard_typing': 40, 'wind': 40, 'footsteps': 40, 'frog': 40, 'cow': 40, 'brushing_teeth': 40, 'car_horn': 40, 'crackling_fire': 40, 'helicopter': 40, 'drinking_sipping': 40, 'rain': 40, 'insects': 40, 'laughing': 40, 'hen': 40, 'engine': 40, 'breathing': 40, 'crying_baby': 40, 'hand_saw': 40, 'coughing': 40, 'glass_breaking': 40, 'snoring': 40, 'toilet_flush': 40, 'pig': 40, 'washing_machine': 40, 'clock_tick': 40, 'sneezing': 40, 'rooster': 40, 'sea_waves': 40, 'siren': 40, 'cat': 40, 'door_wood_creaks': 40, 'crickets': 40}\n"
     ]
    }
   ],
   "source": [
    "# Load ESC-50 with specific classes (change as needed)\n",
    "# esc50_classes = ['dog', 'cat', 'rooster', 'chainsaw', 'helicopter', 'airplane']\n",
    "esc50_classes = None\n",
    "\n",
    "print(f\"Loading ESC-50 dataset with classes: {esc50_classes}\")\n",
    "esc50_dataset = ESC50Dataset(\n",
    "    root_dir=\"/home/lpala/fedgfe/dataset/Audio/esc50-v2.0.0-full\",\n",
    "    selected_classes=esc50_classes,\n",
    "    split='all',\n",
    "    use_folds=False,\n",
    "    enable_cache=False\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ ESC-50 Dataset loaded!\")\n",
    "print(f\"   Total samples: {len(esc50_dataset)}\")\n",
    "print(f\"   Classes: {esc50_dataset.get_class_names()}\")\n",
    "print(f\"   Samples per class: {esc50_dataset.get_samples_per_class()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 VEGAS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VEGAS dataset with classes: ['dog', 'baby_cry', 'chainsaw']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datautils.dataset_vegas:VEGAS Dataset initialized: 6668 samples, classes: ['baby_cry', 'chainsaw', 'dog'], split: all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ VEGAS Dataset loaded!\n",
      "   Total samples: 6668\n",
      "   Classes: ['baby_cry', 'chainsaw', 'dog']\n",
      "   Samples per class: {'baby_cry': 2059, 'chainsaw': 1824, 'dog': 2785}\n"
     ]
    }
   ],
   "source": [
    "# Load VEGAS with specific classes (change as needed)\n",
    "vegas_classes = ['dog', 'baby_cry', 'chainsaw']\n",
    "\n",
    "print(f\"Loading VEGAS dataset with classes: {vegas_classes}\")\n",
    "vegas_dataset = VEGASDataset(\n",
    "    root_dir=\"/home/lpala/fedgfe/dataset/Audio/VEGAS\",\n",
    "    selected_classes=vegas_classes,\n",
    "    split='all',\n",
    "    enable_cache=False,\n",
    "    load_image=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ VEGAS Dataset loaded!\")\n",
    "print(f\"   Total samples: {len(vegas_dataset)}\")\n",
    "print(f\"   Classes: {vegas_dataset.get_class_names()}\")\n",
    "print(f\"   Samples per class: {vegas_dataset.get_samples_per_class()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Dataset Explorer\n",
    "\n",
    "### 4.1 ESC-50 Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéõÔ∏è  ESC-50 INTERACTIVE EXPLORER\n",
      "============================================================\n",
      "Use the slider below to explore different samples\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168a15ab99c745558f5ce442dbc022a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Sample:', max=1999), Output()),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def explore_esc50_sample(sample_idx):\n",
    "    \"\"\"Interactive ESC-50 sample explorer\"\"\"\n",
    "    sample = esc50_dataset[sample_idx]\n",
    "    \n",
    "    # Display info\n",
    "    display_sample_info(sample)\n",
    "    \n",
    "    # Display image\n",
    "    display_image(sample['image'], f\"Image - {sample['class_name']}\")\n",
    "    \n",
    "    # Display waveform\n",
    "    plot_waveform(\n",
    "        sample['audio'], \n",
    "        16000, \n",
    "        f\"Waveform - {sample['class_name']}\"\n",
    "    )\n",
    "    \n",
    "    # Display spectrogram\n",
    "    plot_spectrogram(\n",
    "        sample['audio'], \n",
    "        16000, \n",
    "        f\"Spectrogram - {sample['class_name']}\"\n",
    "    )\n",
    "    \n",
    "    # Play audio\n",
    "    print(\"\\nüéµ Audio Player:\")\n",
    "    display(play_audio(sample['audio'], 16000))\n",
    "    \n",
    "    return sample\n",
    "\n",
    "# Create interactive widget\n",
    "sample_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(esc50_dataset)-1,\n",
    "    step=1,\n",
    "    description='Sample:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéõÔ∏è  ESC-50 INTERACTIVE EXPLORER\")\n",
    "print(\"=\"*60)\n",
    "print(\"Use the slider below to explore different samples\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "interactive_plot = interactive(explore_esc50_sample, sample_idx=sample_slider)\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 VEGAS Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéõÔ∏è  VEGAS INTERACTIVE EXPLORER\n",
      "============================================================\n",
      "Use the slider below to explore different samples\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec4f0894d104005826a59173820a7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Sample:', max=6667), Output()),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def explore_vegas_sample(sample_idx):\n",
    "    \"\"\"Interactive VEGAS sample explorer\"\"\"\n",
    "    sample = vegas_dataset[sample_idx]\n",
    "    \n",
    "    # Display info\n",
    "    display_sample_info(sample)\n",
    "    \n",
    "    # Display image\n",
    "    if 'image' in sample:\n",
    "        display_image(sample['image'], f\"Image - {sample['class_name']}\")\n",
    "    \n",
    "    # Display waveform\n",
    "    plot_waveform(\n",
    "        sample['audio'], \n",
    "        16000, \n",
    "        f\"Waveform - {sample['class_name']}\"\n",
    "    )\n",
    "    \n",
    "    # Display spectrogram\n",
    "    plot_spectrogram(\n",
    "        sample['audio'], \n",
    "        16000, \n",
    "        f\"Spectrogram - {sample['class_name']}\"\n",
    "    )\n",
    "    \n",
    "    # Play audio\n",
    "    print(\"\\nüéµ Audio Player:\")\n",
    "    display(play_audio(sample['audio'], 16000))\n",
    "    \n",
    "    return sample\n",
    "\n",
    "# Create interactive widget\n",
    "vegas_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(vegas_dataset)-1,\n",
    "    step=1,\n",
    "    description='Sample:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéõÔ∏è  VEGAS INTERACTIVE EXPLORER\")\n",
    "print(\"=\"*60)\n",
    "print(\"Use the slider below to explore different samples\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "interactive_vegas = interactive(explore_vegas_sample, sample_idx=vegas_slider)\n",
    "display(interactive_vegas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Class-based Explorer\n",
    "\n",
    "### 5.1 ESC-50 by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ ESC-50 CLASS-BASED EXPLORER\n",
      "============================================================\n",
      "Select a class and browse through its samples\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d940fad813874f449539edb39523cedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Class:', options=('airplane', 'breathing', 'brushing_teeth', 'can_‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def explore_esc50_by_class(class_name, sample_in_class):\n",
    "    \"\"\"Explore ESC-50 samples by class\"\"\"\n",
    "    # Get all samples of this class\n",
    "    class_samples = [i for i in range(len(esc50_dataset)) \n",
    "                     if esc50_dataset[i]['class_name'] == class_name]\n",
    "    \n",
    "    if not class_samples:\n",
    "        print(f\"No samples found for class: {class_name}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(class_samples)} samples for class '{class_name}'\")\n",
    "    \n",
    "    sample_idx = class_samples[sample_in_class % len(class_samples)]\n",
    "    sample = esc50_dataset[sample_idx]\n",
    "    \n",
    "    # Display info\n",
    "    print(f\"\\nShowing sample {sample_in_class + 1} of {len(class_samples)}\")\n",
    "    display_sample_info(sample)\n",
    "    \n",
    "    # Display image\n",
    "    display_image(sample['image'], f\"Image - {sample['class_name']}\")\n",
    "    \n",
    "    # Display waveform\n",
    "    plot_waveform(\n",
    "        sample['audio'], \n",
    "        16000, \n",
    "        f\"Waveform - {sample['class_name']}\"\n",
    "    )\n",
    "    \n",
    "    # Play audio\n",
    "    print(\"\\nüéµ Audio Player:\")\n",
    "    display(play_audio(sample['audio'], 16000))\n",
    "\n",
    "# Create dropdown and slider\n",
    "class_dropdown = widgets.Dropdown(\n",
    "    options=esc50_dataset.get_class_names(),\n",
    "    description='Class:',\n",
    ")\n",
    "\n",
    "class_sample_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Sample #:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ ESC-50 CLASS-BASED EXPLORER\")\n",
    "print(\"=\"*60)\n",
    "print(\"Select a class and browse through its samples\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "interactive_class = interactive(\n",
    "    explore_esc50_by_class, \n",
    "    class_name=class_dropdown,\n",
    "    sample_in_class=class_sample_slider\n",
    ")\n",
    "display(interactive_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 VEGAS by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_vegas_by_class(class_name, sample_in_class):\n",
    "    \"\"\"Explore VEGAS samples by class\"\"\"\n",
    "    # Get all samples of this class\n",
    "    class_samples = [i for i in range(len(vegas_dataset)) \n",
    "                     if vegas_dataset[i]['class_name'] == class_name]\n",
    "    \n",
    "    if not class_samples:\n",
    "        print(f\"No samples found for class: {class_name}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(class_samples)} samples for class '{class_name}'\")\n",
    "    \n",
    "    sample_idx = class_samples[sample_in_class % len(class_samples)]\n",
    "    sample = vegas_dataset[sample_idx]\n",
    "    \n",
    "    # Display info\n",
    "    print(f\"\\nShowing sample {sample_in_class + 1} of {len(class_samples)}\")\n",
    "    display_sample_info(sample)\n",
    "    \n",
    "    # Display image\n",
    "    display_image(sample['image'], f\"Image - {sample['class_name']}\")\n",
    "    \n",
    "    # Display waveform\n",
    "    plot_waveform(\n",
    "        sample['audio'], \n",
    "        16000, \n",
    "        f\"Waveform - {sample['class_name']}\"\n",
    "    )\n",
    "    \n",
    "    # Play audio\n",
    "    print(\"\\nüéµ Audio Player:\")\n",
    "    display(play_audio(sample['audio'], 16000))\n",
    "\n",
    "# Create dropdown and slider\n",
    "vegas_class_dropdown = widgets.Dropdown(\n",
    "    options=vegas_dataset.get_class_names(),\n",
    "    description='Class:',\n",
    ")\n",
    "\n",
    "vegas_class_sample_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Sample #:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ VEGAS CLASS-BASED EXPLORER\")\n",
    "print(\"=\"*60)\n",
    "print(\"Select a class and browse through its samples\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "interactive_vegas_class = interactive(\n",
    "    explore_vegas_by_class, \n",
    "    class_name=vegas_class_dropdown,\n",
    "    sample_in_class=vegas_class_sample_slider\n",
    ")\n",
    "display(interactive_vegas_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(dataset, title):\n",
    "    \"\"\"Plot class distribution\"\"\"\n",
    "    samples_per_class = dataset.get_samples_per_class()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(samples_per_class.keys(), samples_per_class.values())\n",
    "    plt.title(f\"{title} - Class Distribution\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Number of Samples\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nüìä {title} Statistics:\")\n",
    "    print(f\"   Total samples: {len(dataset)}\")\n",
    "    print(f\"   Number of classes: {len(samples_per_class)}\")\n",
    "    print(f\"   Min samples per class: {min(samples_per_class.values())}\")\n",
    "    print(f\"   Max samples per class: {max(samples_per_class.values())}\")\n",
    "    print(f\"   Avg samples per class: {sum(samples_per_class.values()) / len(samples_per_class):.1f}\")\n",
    "\n",
    "# Plot ESC-50 distribution\n",
    "plot_class_distribution(esc50_dataset, \"ESC-50\")\n",
    "\n",
    "# Plot VEGAS distribution\n",
    "plot_class_distribution(vegas_dataset, \"VEGAS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Audio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio_statistics(dataset, dataset_name, num_samples=20):\n",
    "    \"\"\"Analyze audio statistics across dataset\"\"\"\n",
    "    print(f\"\\nüî¨ Analyzing {dataset_name} audio statistics (first {num_samples} samples)...\\n\")\n",
    "    \n",
    "    amplitudes = []\n",
    "    durations = []\n",
    "    \n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        sample = dataset[i]\n",
    "        audio = sample['audio']\n",
    "        \n",
    "        amplitudes.append(audio.abs().mean().item())\n",
    "        durations.append(len(audio) / 16000)\n",
    "    \n",
    "    print(f\"üìà Audio Statistics:\")\n",
    "    print(f\"   Mean amplitude: {np.mean(amplitudes):.4f}\")\n",
    "    print(f\"   Std amplitude: {np.std(amplitudes):.4f}\")\n",
    "    print(f\"   Mean duration: {np.mean(durations):.2f}s\")\n",
    "    print(f\"   Std duration: {np.std(durations):.2f}s\")\n",
    "    \n",
    "    # Plot amplitude distribution\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(amplitudes, bins=20, edgecolor='black')\n",
    "    plt.title(f\"{dataset_name} - Amplitude Distribution\")\n",
    "    plt.xlabel(\"Mean Amplitude\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(durations, bins=20, edgecolor='black')\n",
    "    plt.title(f\"{dataset_name} - Duration Distribution\")\n",
    "    plt.xlabel(\"Duration (s)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze both datasets\n",
    "analyze_audio_statistics(esc50_dataset, \"ESC-50\", num_samples=20)\n",
    "analyze_audio_statistics(vegas_dataset, \"VEGAS\", num_samples=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare Samples from Different Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_classes(dataset, class1, class2):\n",
    "    \"\"\"Compare audio samples from two different classes\"\"\"\n",
    "    # Get first sample of each class\n",
    "    sample1 = None\n",
    "    sample2 = None\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        sample = dataset[i]\n",
    "        if sample['class_name'] == class1 and sample1 is None:\n",
    "            sample1 = sample\n",
    "        if sample['class_name'] == class2 and sample2 is None:\n",
    "            sample2 = sample\n",
    "        if sample1 and sample2:\n",
    "            break\n",
    "    \n",
    "    if not sample1 or not sample2:\n",
    "        print(\"Could not find samples for comparison\")\n",
    "        return\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "    \n",
    "    # Waveforms\n",
    "    time1 = torch.arange(0, len(sample1['audio'])) / 16000\n",
    "    axes[0, 0].plot(time1, sample1['audio'].numpy())\n",
    "    axes[0, 0].set_title(f\"Waveform - {class1}\")\n",
    "    axes[0, 0].set_xlabel(\"Time (s)\")\n",
    "    axes[0, 0].set_ylabel(\"Amplitude\")\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    time2 = torch.arange(0, len(sample2['audio'])) / 16000\n",
    "    axes[0, 1].plot(time2, sample2['audio'].numpy())\n",
    "    axes[0, 1].set_title(f\"Waveform - {class2}\")\n",
    "    axes[0, 1].set_xlabel(\"Time (s)\")\n",
    "    axes[0, 1].set_ylabel(\"Amplitude\")\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Spectrograms\n",
    "    axes[1, 0].specgram(sample1['audio'].numpy(), Fs=16000, cmap='viridis')\n",
    "    axes[1, 0].set_title(f\"Spectrogram - {class1}\")\n",
    "    axes[1, 0].set_xlabel(\"Time (s)\")\n",
    "    axes[1, 0].set_ylabel(\"Frequency (Hz)\")\n",
    "    \n",
    "    axes[1, 1].specgram(sample2['audio'].numpy(), Fs=16000, cmap='viridis')\n",
    "    axes[1, 1].set_title(f\"Spectrogram - {class2}\")\n",
    "    axes[1, 1].set_xlabel(\"Time (s)\")\n",
    "    axes[1, 1].set_ylabel(\"Frequency (Hz)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Audio players\n",
    "    print(f\"\\nüéµ Audio Player - {class1}:\")\n",
    "    display(play_audio(sample1['audio'], 16000))\n",
    "    \n",
    "    print(f\"\\nüéµ Audio Player - {class2}:\")\n",
    "    display(play_audio(sample2['audio'], 16000))\n",
    "\n",
    "# Create interactive comparison\n",
    "class1_dropdown = widgets.Dropdown(\n",
    "    options=esc50_dataset.get_class_names(),\n",
    "    description='Class 1:',\n",
    "    value=esc50_dataset.get_class_names()[0]\n",
    ")\n",
    "\n",
    "class2_dropdown = widgets.Dropdown(\n",
    "    options=esc50_dataset.get_class_names(),\n",
    "    description='Class 2:',\n",
    "    value=esc50_dataset.get_class_names()[1] if len(esc50_dataset.get_class_names()) > 1 else esc50_dataset.get_class_names()[0]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîÄ CLASS COMPARISON TOOL\")\n",
    "print(\"=\"*60)\n",
    "print(\"Compare audio samples from two different classes\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "interactive_compare = interactive(\n",
    "    lambda c1, c2: compare_classes(esc50_dataset, c1, c2),\n",
    "    c1=class1_dropdown,\n",
    "    c2=class2_dropdown\n",
    ")\n",
    "display(interactive_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Sample\n",
    "\n",
    "Save a specific sample to disk for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_sample(dataset, sample_idx, output_dir=\"/tmp/audio_samples\"):\n",
    "    \"\"\"Export a sample to disk\"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    sample = dataset[sample_idx]\n",
    "    class_name = sample['class_name']\n",
    "    \n",
    "    # Save audio\n",
    "    audio_path = os.path.join(output_dir, f\"{class_name}_{sample_idx}.wav\")\n",
    "    torchaudio.save(audio_path, sample['audio'].unsqueeze(0), 16000)\n",
    "    \n",
    "    # Save image\n",
    "    image_path = os.path.join(output_dir, f\"{class_name}_{sample_idx}.png\")\n",
    "    # Denormalize and save\n",
    "    image_tensor = sample['image']\n",
    "    if image_tensor.min() < 0:\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        image_tensor = image_tensor * std + mean\n",
    "    image_tensor = torch.clamp(image_tensor, 0, 1)\n",
    "    image = image_tensor.permute(1, 2, 0).numpy()\n",
    "    Image.fromarray((image * 255).astype(np.uint8)).save(image_path)\n",
    "    \n",
    "    print(f\"‚úÖ Sample exported to:\")\n",
    "    print(f\"   Audio: {audio_path}\")\n",
    "    print(f\"   Image: {image_path}\")\n",
    "\n",
    "# Example: export first ESC-50 sample\n",
    "# export_sample(esc50_dataset, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "This notebook provides:\n",
    "- ‚úÖ Interactive exploration of ESC-50 and VEGAS datasets\n",
    "- ‚úÖ Audio playback in notebook\n",
    "- ‚úÖ Waveform and spectrogram visualization\n",
    "- ‚úÖ Class-based browsing\n",
    "- ‚úÖ Dataset statistics and analysis\n",
    "- ‚úÖ Sample comparison tools\n",
    "- ‚úÖ Export functionality\n",
    "\n",
    "### Quick Access:\n",
    "- **Section 4**: Interactive explorers for both datasets\n",
    "- **Section 5**: Class-based exploration\n",
    "- **Section 8**: Compare samples from different classes\n",
    "\n",
    "Enjoy exploring your audio datasets! üéµ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
